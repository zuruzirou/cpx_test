{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP5/51tTmBVWQxVqdFOqIgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuruzirou/cpx_test/blob/main/lora_instruct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOZ4C-TyHBcA",
        "outputId": "e0a7b9b7-ada7-42b5-f57d-7cd82da733db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Googleドライブのマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 作業フォルダへの移動\n",
        "import os\n",
        "os.makedirs(\"/content/drive/My Drive/work\", exist_ok=True)\n",
        "%cd '/content/drive/My Drive/work'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcrZS2YgH3cD",
        "outputId": "915052ce-f8f9-4c76-d112-a116701d0e6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# リポジトリのクローン\n",
        "!git clone https://github.com/leehanchung/lora-instruct\n",
        "%cd lora-instruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s03fI9otH7FS",
        "outputId": "c0dc9622-2dd4-44e2-e617-88d1ab2f529f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lora-instruct'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 67 (delta 27), reused 58 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), 20.87 MiB | 5.02 MiB/s, done.\n",
            "Updating files: 100% (24/24), done.\n",
            "/content/drive/MyDrive/work/lora-instruct/lora-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXExVirAac6i",
        "outputId": "73715070-6b50-4fba-fbcf-9b4436a43b32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/work/lora-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# poetryをrequirements.txtで出力\n",
        "!pip install poetry\n",
        "!poetry export --without-hashes --with dev --output requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lz3hEA0ICsS",
        "outputId": "4dee3c5d-0944-4526-f209-ad5c5a51e56e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: poetry in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: build<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.10.0)\n",
            "Requirement already satisfied: cachecontrol[filecache]<0.13.0,>=0.12.9 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.12.11)\n",
            "Requirement already satisfied: cleo<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.0.1)\n",
            "Requirement already satisfied: crashtest<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.4.1)\n",
            "Requirement already satisfied: dulwich<0.22.0,>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.21.5)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (3.12.0)\n",
            "Requirement already satisfied: html5lib<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.1)\n",
            "Requirement already satisfied: installer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.7.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (4.17.3)\n",
            "Requirement already satisfied: keyring<24.0.0,>=23.9.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (23.13.1)\n",
            "Requirement already satisfied: lockfile<0.13.0,>=0.12.2 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.12.2)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from poetry) (23.1)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (4.8.0)\n",
            "Requirement already satisfied: pkginfo<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.9.6)\n",
            "Requirement already satisfied: platformdirs<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.6.2)\n",
            "Requirement already satisfied: poetry-core==1.5.2 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.5.2)\n",
            "Requirement already satisfied: poetry-plugin-export<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.3.1)\n",
            "Requirement already satisfied: pyproject-hooks<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.18 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.27.1)\n",
            "Requirement already satisfied: requests-toolbelt<0.11.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.10.1)\n",
            "Requirement already satisfied: shellingham<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.5.0.post1)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.0.1)\n",
            "Requirement already satisfied: tomlkit!=0.11.2,!=0.11.3,<1.0.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.11.8)\n",
            "Requirement already satisfied: trove-classifiers>=2022.5.19 in /usr/local/lib/python3.10/dist-packages (from poetry) (2023.5.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.26.15)\n",
            "Requirement already satisfied: virtualenv!=20.4.5,!=20.4.6,<21.0.0,>=20.4.3 in /usr/local/lib/python3.10/dist-packages (from poetry) (20.21.1)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.13.0,>=0.12.9->poetry) (1.0.5)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from cleo<3.0.0,>=2.0.0->poetry) (2.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib<2.0,>=1.0->poetry) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib<2.0,>=1.0->poetry) (0.5.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry) (0.19.3)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.10/dist-packages (from keyring<24.0.0,>=23.9.0->poetry) (3.2.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.11.4 in /usr/local/lib/python3.10/dist-packages (from keyring<24.0.0,>=23.9.0->poetry) (6.6.0)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.10/dist-packages (from keyring<24.0.0,>=23.9.0->poetry) (3.3.3)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from keyring<24.0.0,>=23.9.0->poetry) (0.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.18->poetry) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.18->poetry) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.18->poetry) (3.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.4.5,!=20.4.6,<21.0.0,>=20.4.3->poetry) (0.3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.11.4->keyring<24.0.0,>=23.9.0->poetry) (3.15.0)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.10/dist-packages (from SecretStorage>=3.2->keyring<24.0.0,>=23.9.0->poetry) (40.0.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from jaraco.classes->keyring<24.0.0,>=23.9.0->poetry) (9.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring<24.0.0,>=23.9.0->poetry) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring<24.0.0,>=23.9.0->poetry) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEC-etCuJB6y",
        "outputId": "dbd1aa96-3d5f-4a7c-8bd7-d80c8aab53f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Ignoring appnope: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and platform_system == \"Darwin\" or python_version >= \"3.10\" and python_version < \"4.0\" and sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring cffi: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and implementation_name == \"pypy\"' don't match your environment\n",
            "Ignoring pycparser: markers 'python_version >= \"3.10\" and python_version < \"4.0\" and implementation_name == \"pypy\"' don't match your environment\n",
            "Ignoring pywin32: markers 'sys_platform == \"win32\" and platform_python_implementation != \"PyPy\" and python_version >= \"3.10\" and python_version < \"4.0\"' don't match your environment\n",
            "Collecting accelerate==0.18.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles==23.1.0 (from -r requirements.txt (line 2))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp==3.8.4 (from -r requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal==1.3.1 (from -r requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: anyio==3.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.6.2)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.4.4)\n",
            "Collecting asttokens==2.2.1 (from -r requirements.txt (line 9))\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout==4.0.2 (from -r requirements.txt (line 10))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (23.1.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
            "Collecting bitsandbytes==0.38.1 (from -r requirements.txt (line 13))\n",
            "  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==23.3.0 (from -r requirements.txt (line 14))\n",
            "  Downloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools==5.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (5.3.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2022.12.7)\n",
            "Collecting chardet==5.1.0 (from -r requirements.txt (line 19))\n",
            "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==3.1.0 (from -r requirements.txt (line 20))\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (8.1.3)\n",
            "Collecting cmake==3.26.3 (from -r requirements.txt (line 22))\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.6 (from -r requirements.txt (line 23))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting comm==0.1.3 (from -r requirements.txt (line 24))\n",
            "  Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: contourpy==1.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.0.7)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (0.11.0)\n",
            "Collecting datasets==2.12.0 (from -r requirements.txt (line 27))\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy==1.6.7 (from -r requirements.txt (line 28))\n",
            "  Downloading debugpy-1.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==5.1.1 (from -r requirements.txt (line 29))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting dill==0.3.6 (from -r requirements.txt (line 30))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distlib==0.3.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.3.6)\n",
            "Collecting docker-pycreds==0.4.0 (from -r requirements.txt (line 32))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting einops==0.6.1 (from -r requirements.txt (line 33))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (0.4)\n",
            "Requirement already satisfied: exceptiongroup==1.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (1.1.1)\n",
            "Collecting executing==1.2.0 (from -r requirements.txt (line 36))\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting fastapi==0.95.1 (from -r requirements.txt (line 37))\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy==0.3.0 (from -r requirements.txt (line 38))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock==3.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (3.12.0)\n",
            "Collecting fire==0.5.0 (from -r requirements.txt (line 40))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flake8==6.0.0 (from -r requirements.txt (line 41))\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools==4.39.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (4.39.3)\n",
            "Collecting frozenlist==1.3.3 (from -r requirements.txt (line 43))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec==2023.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (2023.4.0)\n",
            "Collecting gitdb==4.0.10 (from -r requirements.txt (line 46))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython==3.1.31 (from -r requirements.txt (line 47))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio-client==0.2.0 (from -r requirements.txt (line 48))\n",
            "  Downloading gradio_client-0.2.0-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.28.3 (from -r requirements.txt (line 49))\n",
            "  Downloading gradio-3.28.3-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11==0.14.0 (from -r requirements.txt (line 50))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==0.17.0 (from -r requirements.txt (line 51))\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx==0.24.0 (from -r requirements.txt (line 52))\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.14.1 (from -r requirements.txt (line 53))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (3.4)\n",
            "Requirement already satisfied: iniconfig==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 55)) (2.0.0)\n",
            "Collecting ipykernel==6.22.0 (from -r requirements.txt (line 56))\n",
            "  Downloading ipykernel-6.22.0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.13.2 (from -r requirements.txt (line 57))\n",
            "  Downloading ipython-8.13.2-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.7/797.7 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort==5.12.0 (from -r requirements.txt (line 58))\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi==0.18.2 (from -r requirements.txt (line 59))\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (3.1.2)\n",
            "Requirement already satisfied: jsonschema==4.17.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (4.17.3)\n",
            "Collecting jupyter-client==8.2.0 (from -r requirements.txt (line 62))\n",
            "  Downloading jupyter_client-8.2.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-core==5.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (5.3.0)\n",
            "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 64)) (1.4.4)\n",
            "Collecting linkify-it-py==2.0.2 (from -r requirements.txt (line 65))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: lit==16.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (16.0.3)\n",
            "Collecting loralib==0.1.1 (from -r requirements.txt (line 67))\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: markdown-it-py==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 70)) (2.1.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (0.1.6)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 72)) (3.7.1)\n",
            "Collecting mccabe==0.7.0 (from -r requirements.txt (line 73))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting mdit-py-plugins==0.3.3 (from -r requirements.txt (line 74))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 75)) (0.1.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 76)) (1.3.0)\n",
            "Collecting multidict==6.0.4 (from -r requirements.txt (line 77))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess==0.70.14 (from -r requirements.txt (line 78))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions==1.0.0 (from -r requirements.txt (line 79))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (1.5.6)\n",
            "Requirement already satisfied: networkx==3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 81)) (3.1)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 82))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from -r requirements.txt (line 83))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from -r requirements.txt (line 84))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from -r requirements.txt (line 85))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from -r requirements.txt (line 86))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from -r requirements.txt (line 87))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from -r requirements.txt (line 88))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from -r requirements.txt (line 89))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from -r requirements.txt (line 90))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from -r requirements.txt (line 91))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from -r requirements.txt (line 92))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from -r requirements.txt (line 93))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson==3.8.11 (from -r requirements.txt (line 94))\n",
            "  Downloading orjson-3.8.11-cp310-cp310-manylinux_2_28_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 95)) (23.1)\n",
            "Collecting pandas==2.0.1 (from -r requirements.txt (line 96))\n",
            "  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 97)) (0.8.3)\n",
            "Collecting pathspec==0.11.1 (from -r requirements.txt (line 98))\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Collecting pathtools==0.1.2 (from -r requirements.txt (line 99))\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft (from -r requirements.txt (line 100))\n",
            "  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 101)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 102)) (0.7.5)\n",
            "Collecting pillow==9.5.0 (from -r requirements.txt (line 103))\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs==3.5.0 (from -r requirements.txt (line 104))\n",
            "  Downloading platformdirs-3.5.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pluggy==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 105)) (1.0.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.38 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 106)) (3.0.38)\n",
            "Collecting protobuf==4.22.4 (from -r requirements.txt (line 107))\n",
            "  Downloading protobuf-4.22.4-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 108)) (5.9.5)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 109)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 110))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pyarrow==12.0.0 (from -r requirements.txt (line 111))\n",
            "  Downloading pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle==2.10.0 (from -r requirements.txt (line 112))\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic==1.10.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 114)) (1.10.7)\n",
            "Collecting pydub==0.25.1 (from -r requirements.txt (line 115))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pyflakes==3.0.1 (from -r requirements.txt (line 116))\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments==2.15.1 (from -r requirements.txt (line 117))\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 118)) (3.0.9)\n",
            "Collecting pyproject-api==1.5.1 (from -r requirements.txt (line 119))\n",
            "  Downloading pyproject_api-1.5.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pyrsistent==0.19.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 120)) (0.19.3)\n",
            "Collecting pytest==7.3.1 (from -r requirements.txt (line 121))\n",
            "  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 122)) (2.8.2)\n",
            "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 123))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting python-multipart==0.0.6 (from -r requirements.txt (line 124))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2023.3 (from -r requirements.txt (line 125))\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 127)) (6.0)\n",
            "Collecting pyzmq==25.0.2 (from -r requirements.txt (line 128))\n",
            "  Downloading pyzmq-25.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex==2023.5.5 (from -r requirements.txt (line 129))\n",
            "  Downloading regex-2023.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.30.0 (from -r requirements.txt (line 130))\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses==0.18.0 (from -r requirements.txt (line 131))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting semantic-version==2.10.0 (from -r requirements.txt (line 132))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentencepiece==0.1.99 (from -r requirements.txt (line 133))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk==1.21.1 (from -r requirements.txt (line 134))\n",
            "  Downloading sentry_sdk-1.21.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle==1.3.2 (from -r requirements.txt (line 135))\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools==67.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 136)) (67.7.2)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 137)) (1.16.0)\n",
            "Collecting smmap==5.0.0 (from -r requirements.txt (line 138))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sniffio==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 139)) (1.3.0)\n",
            "Collecting stack-data==0.6.2 (from -r requirements.txt (line 140))\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting starlette==0.26.1 (from -r requirements.txt (line 141))\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.11.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 142)) (1.11.1)\n",
            "Requirement already satisfied: termcolor==2.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 143)) (2.3.0)\n",
            "Collecting tokenize-rt==5.0.0 (from -r requirements.txt (line 144))\n",
            "  Downloading tokenize_rt-5.0.0-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting tokenizers==0.13.3 (from -r requirements.txt (line 145))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 146)) (2.0.1)\n",
            "Requirement already satisfied: toolz==0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 147)) (0.12.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 148)) (2.0.0+cu118)\n",
            "Requirement already satisfied: tornado==6.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 149)) (6.3.1)\n",
            "Collecting tox==4.5.1 (from -r requirements.txt (line 150))\n",
            "  Downloading tox-4.5.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 151)) (4.65.0)\n",
            "Collecting traitlets==5.9.0 (from -r requirements.txt (line 152))\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.28.1 (from -r requirements.txt (line 153))\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 154)) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 155)) (4.5.0)\n",
            "Requirement already satisfied: tzdata==2023.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 156)) (2023.3)\n",
            "Collecting uc-micro-py==1.0.2 (from -r requirements.txt (line 157))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Collecting urllib3==2.0.2 (from -r requirements.txt (line 158))\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.22.0 (from -r requirements.txt (line 159))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv==20.23.0 (from -r requirements.txt (line 160))\n",
            "  Using cached virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "Collecting wandb==0.15.2 (from -r requirements.txt (line 161))\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth==0.2.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 162)) (0.2.6)\n",
            "Collecting websockets==11.0.2 (from -r requirements.txt (line 163))\n",
            "  Downloading websockets-11.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel==0.40.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 164)) (0.40.0)\n",
            "Collecting xxhash==3.2.0 (from -r requirements.txt (line 165))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl==1.9.2 (from -r requirements.txt (line 166))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpy, fire, pathtools\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=a36d2c0b38398c8e7adb32ade9faeaf91a71419510523f629abe64f926f54748\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=93aa5c04871039ec524832bd9e147147dc0387656382f178641f8ac283d81e26\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=d0dbdb90e124836c3e9166bd16e110cdc861e4b9c6ea438583f31cced06d2b56\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built ffmpy fire pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pytz, pydub, pure-eval, pathtools, ffmpy, executing, cmake, bitsandbytes, xxhash, websockets, urllib3, uc-micro-py, traitlets, tokenize-rt, smmap, setproctitle, semantic-version, regex, pyzmq, python-multipart, python-dotenv, pytest, pyproject-api, pygments, pyflakes, pycodestyle, protobuf, platformdirs, pillow, pathspec, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, mypy-extensions, multidict, mccabe, loralib, jedi, isort, h11, frozenlist, fire, einops, docker-pycreds, dill, decorator, debugpy, colorama, charset-normalizer, chardet, async-timeout, asttokens, aiofiles, yarl, virtualenv, uvicorn, starlette, stack-data, sentry-sdk, requests, pyarrow, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, mdit-py-plugins, linkify-it-py, httpcore, gitdb, flake8, comm, black, aiosignal, tox, responses, jupyter-client, ipython, huggingface-hub, httpx, gitpython, fastapi, aiohttp, wandb, transformers, ipykernel, gradio-client, gradio, datasets, accelerate, peft\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.7.1\n",
            "    Uninstalling pytz-2022.7.1:\n",
            "      Successfully uninstalled pytz-2022.7.1\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.25.2\n",
            "    Uninstalling cmake-3.25.2:\n",
            "      Successfully uninstalled cmake-3.25.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.10.31\n",
            "    Uninstalling regex-2022.10.31:\n",
            "      Successfully uninstalled regex-2022.10.31\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 23.2.1\n",
            "    Uninstalling pyzmq-23.2.1:\n",
            "      Successfully uninstalled pyzmq-23.2.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.2.2\n",
            "    Uninstalling pytest-7.2.2:\n",
            "      Successfully uninstalled pytest-7.2.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.14.0\n",
            "    Uninstalling Pygments-2.14.0:\n",
            "      Successfully uninstalled Pygments-2.14.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 2.6.2\n",
            "    Uninstalling platformdirs-2.6.2:\n",
            "      Successfully uninstalled platformdirs-2.6.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: debugpy\n",
            "    Found existing installation: debugpy 1.6.6\n",
            "    Uninstalling debugpy-1.6.6:\n",
            "      Successfully uninstalled debugpy-1.6.6\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: virtualenv\n",
            "    Found existing installation: virtualenv 20.21.1\n",
            "    Uninstalling virtualenv-20.21.1:\n",
            "      Successfully uninstalled virtualenv-20.21.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel~=5.5.6, but you have ipykernel 6.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.34.0, but you have ipython 8.13.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.1 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 12.0.0 which is incompatible.\n",
            "poetry 1.4.2 requires platformdirs<3.0.0,>=2.5.2, but you have platformdirs 3.5.0 which is incompatible.\n",
            "poetry 1.4.2 requires urllib3<2.0.0,>=1.26.0, but you have urllib3 2.0.2 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.18.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 asttokens-2.2.1 async-timeout-4.0.2 bitsandbytes-0.38.1 black-23.3.0 chardet-5.1.0 charset-normalizer-3.1.0 cmake-3.26.3 colorama-0.4.6 comm-0.1.3 datasets-2.12.0 debugpy-1.6.7 decorator-5.1.1 dill-0.3.6 docker-pycreds-0.4.0 einops-0.6.1 executing-1.2.0 fastapi-0.95.1 ffmpy-0.3.0 fire-0.5.0 flake8-6.0.0 frozenlist-1.3.3 gitdb-4.0.10 gitpython-3.1.31 gradio-3.28.3 gradio-client-0.2.0 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.14.1 ipykernel-6.22.0 ipython-8.13.2 isort-5.12.0 jedi-0.18.2 jupyter-client-8.2.0 linkify-it-py-2.0.2 loralib-0.1.1 mccabe-0.7.0 mdit-py-plugins-0.3.3 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.8.11 pandas-2.0.1 pathspec-0.11.1 pathtools-0.1.2 peft-0.3.0 pillow-9.5.0 platformdirs-3.5.0 protobuf-4.22.4 pure-eval-0.2.2 pyarrow-12.0.0 pycodestyle-2.10.0 pydub-0.25.1 pyflakes-3.0.1 pygments-2.15.1 pyproject-api-1.5.1 pytest-7.3.1 python-dotenv-1.0.0 python-multipart-0.0.6 pytz-2023.3 pyzmq-25.0.2 regex-2023.5.5 requests-2.30.0 responses-0.18.0 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-1.21.1 setproctitle-1.3.2 smmap-5.0.0 stack-data-0.6.2 starlette-0.26.1 tokenize-rt-5.0.0 tokenizers-0.13.3 tox-4.5.1 traitlets-5.9.0 transformers-4.28.1 uc-micro-py-1.0.2 urllib3-2.0.2 uvicorn-0.22.0 virtualenv-20.23.0 wandb-0.15.2 websockets-11.0.2 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "debugpy",
                  "decorator",
                  "numpy",
                  "pygments",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA ファインチューニングの実行\n",
        "!python finetune.py \\\n",
        "    --base_model 'cyberagent/open-calm-7b' \\\n",
        "    --data_path './dataset/code_alpaca_20k.json' \\\n",
        "    --output_dir './lora-calm7b'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2J33gSGJnFT",
        "outputId": "8bebd2c5-1288-4960-f249-1425b2612fc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-17 15:58:40.284614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-1iy3j2rwst2f9 --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "\n",
            "\n",
            "\n",
            "LoRA fine-tuning model with params:\n",
            "base_model: cyberagent/open-calm-7b\n",
            "data_path: ./dataset/code_alpaca_20k.json\n",
            "output_dir: ./lora-calm7b\n",
            "batch_size: 128\n",
            "micro_batch_size: 4\n",
            "num_epochs: 3\n",
            "learning_rate: 0.0003\n",
            "cutoff_len: 256\n",
            "val_set_size: 2000\n",
            "lora_r: 8\n",
            "lora_alpha: 16\n",
            "lora_dropout: 0.05\n",
            "lora_target_modules: ['query_key_value', 'xxx']\n",
            "train_on_inputs: True\n",
            "add_eos_token: False\n",
            "group_by_length: False\n",
            "resume_from_checkpoint: False\n",
            "prompt template: alpaca\n",
            "\n",
            "device map: auto\n",
            "Downloading (…)lve/main/config.json: 100% 611/611 [00:00<00:00, 3.03MB/s]\n",
            "Downloading (…)model.bin.index.json: 100% 42.0k/42.0k [00:00<00:00, 201kB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading (…)l-00001-of-00002.bin:   0% 0.00/9.93G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   0% 41.9M/9.93G [00:00<00:25, 382MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   1% 94.4M/9.93G [00:00<00:22, 435MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   1% 147M/9.93G [00:00<00:21, 458MB/s] \u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   2% 199M/9.93G [00:00<00:20, 468MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   3% 252M/9.93G [00:00<00:20, 475MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   3% 304M/9.93G [00:00<00:20, 477MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   4% 357M/9.93G [00:00<00:19, 482MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   4% 409M/9.93G [00:00<00:19, 483MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   5% 461M/9.93G [00:00<00:19, 484MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   5% 514M/9.93G [00:01<00:19, 484MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   6% 566M/9.93G [00:01<00:19, 486MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   6% 619M/9.93G [00:01<00:19, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   7% 671M/9.93G [00:01<00:18, 487MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   7% 724M/9.93G [00:01<00:18, 487MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   8% 776M/9.93G [00:01<00:18, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   8% 828M/9.93G [00:01<00:18, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   9% 881M/9.93G [00:01<00:18, 486MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:   9% 933M/9.93G [00:01<00:18, 478MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  10% 986M/9.93G [00:02<00:18, 471MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  10% 1.04G/9.93G [00:02<00:19, 466MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  11% 1.09G/9.93G [00:02<00:18, 470MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  12% 1.14G/9.93G [00:02<00:18, 474MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  12% 1.20G/9.93G [00:02<00:18, 477MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  13% 1.25G/9.93G [00:02<00:18, 480MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  13% 1.30G/9.93G [00:02<00:17, 480MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  14% 1.35G/9.93G [00:02<00:17, 481MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  14% 1.41G/9.93G [00:02<00:17, 480MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  15% 1.46G/9.93G [00:03<00:17, 481MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  15% 1.51G/9.93G [00:03<00:17, 484MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  16% 1.56G/9.93G [00:03<00:17, 485MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  16% 1.61G/9.93G [00:03<00:17, 484MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  17% 1.67G/9.93G [00:03<00:17, 486MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  17% 1.72G/9.93G [00:03<00:16, 486MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  18% 1.77G/9.93G [00:03<00:16, 485MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  18% 1.82G/9.93G [00:03<00:16, 485MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  19% 1.88G/9.93G [00:03<00:17, 453MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  19% 1.93G/9.93G [00:04<00:19, 408MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  20% 1.97G/9.93G [00:04<00:20, 387MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  20% 2.01G/9.93G [00:04<00:21, 376MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  21% 2.06G/9.93G [00:04<00:21, 358MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  21% 2.10G/9.93G [00:04<00:22, 356MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  22% 2.14G/9.93G [00:04<00:21, 357MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  22% 2.18G/9.93G [00:04<00:22, 350MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  22% 2.22G/9.93G [00:04<00:22, 348MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  23% 2.26G/9.93G [00:05<00:21, 359MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  23% 2.32G/9.93G [00:05<00:19, 384MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  24% 2.36G/9.93G [00:05<00:20, 378MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  24% 2.40G/9.93G [00:05<00:20, 360MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  25% 2.44G/9.93G [00:05<00:20, 371MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  25% 2.50G/9.93G [00:05<00:18, 397MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  26% 2.55G/9.93G [00:05<00:17, 419MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  26% 2.60G/9.93G [00:05<00:16, 435MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  27% 2.65G/9.93G [00:05<00:16, 447MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  27% 2.71G/9.93G [00:06<00:15, 452MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  28% 2.76G/9.93G [00:06<00:15, 454MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  28% 2.81G/9.93G [00:06<00:15, 459MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  29% 2.86G/9.93G [00:06<00:15, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  29% 2.92G/9.93G [00:06<00:15, 457MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  30% 2.97G/9.93G [00:06<00:15, 463MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  30% 3.02G/9.93G [00:06<00:14, 466MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  31% 3.07G/9.93G [00:06<00:14, 467MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  31% 3.12G/9.93G [00:07<00:14, 458MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  32% 3.18G/9.93G [00:07<00:14, 461MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  33% 3.23G/9.93G [00:07<00:14, 468MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  33% 3.28G/9.93G [00:07<00:13, 481MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  34% 3.33G/9.93G [00:07<00:13, 488MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  34% 3.39G/9.93G [00:07<00:13, 494MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  35% 3.44G/9.93G [00:07<00:12, 499MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  35% 3.49G/9.93G [00:07<00:12, 503MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  36% 3.54G/9.93G [00:07<00:12, 507MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  36% 3.60G/9.93G [00:07<00:12, 510MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  37% 3.65G/9.93G [00:08<00:12, 511MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  37% 3.70G/9.93G [00:08<00:12, 502MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  38% 3.75G/9.93G [00:08<00:12, 506MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  38% 3.81G/9.93G [00:08<00:12, 508MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  39% 3.86G/9.93G [00:08<00:20, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  39% 3.90G/9.93G [00:08<00:21, 275MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  40% 3.94G/9.93G [00:09<00:22, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  40% 3.98G/9.93G [00:09<00:23, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  40% 4.02G/9.93G [00:09<00:23, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  41% 4.05G/9.93G [00:09<00:24, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  41% 4.08G/9.93G [00:09<00:25, 230MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  41% 4.11G/9.93G [00:09<00:25, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  42% 4.14G/9.93G [00:10<00:27, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  42% 4.17G/9.93G [00:10<00:28, 205MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  42% 4.19G/9.93G [00:10<00:28, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  42% 4.22G/9.93G [00:10<00:29, 195MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  43% 4.24G/9.93G [00:10<00:29, 191MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  43% 4.27G/9.93G [00:10<00:29, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  43% 4.29G/9.93G [00:10<00:29, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  43% 4.31G/9.93G [00:10<00:29, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  44% 4.33G/9.93G [00:11<00:28, 194MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  44% 4.36G/9.93G [00:11<00:27, 206MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  44% 4.39G/9.93G [00:11<00:23, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  45% 4.42G/9.93G [00:11<00:21, 253MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  45% 4.47G/9.93G [00:11<00:20, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  45% 4.50G/9.93G [00:11<00:19, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  46% 4.54G/9.93G [00:11<00:17, 306MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  46% 4.58G/9.93G [00:11<00:16, 329MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  47% 4.63G/9.93G [00:11<00:14, 368MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  47% 4.69G/9.93G [00:12<00:13, 392MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  48% 4.74G/9.93G [00:12<00:12, 411MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  48% 4.78G/9.93G [00:12<00:12, 405MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  49% 4.83G/9.93G [00:12<00:11, 428MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  49% 4.89G/9.93G [00:12<00:11, 446MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  50% 4.94G/9.93G [00:12<00:10, 460MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  50% 4.99G/9.93G [00:12<00:11, 437MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  51% 5.04G/9.93G [00:12<00:12, 394MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  51% 5.09G/9.93G [00:13<00:12, 374MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  52% 5.13G/9.93G [00:13<00:13, 353MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  52% 5.17G/9.93G [00:13<00:14, 332MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  53% 5.21G/9.93G [00:13<00:14, 316MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  53% 5.25G/9.93G [00:13<00:15, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  53% 5.28G/9.93G [00:13<00:15, 302MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  54% 5.32G/9.93G [00:13<00:15, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  54% 5.35G/9.93G [00:13<00:15, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  54% 5.38G/9.93G [00:14<00:15, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  55% 5.41G/9.93G [00:14<00:15, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  55% 5.44G/9.93G [00:14<00:15, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  55% 5.47G/9.93G [00:14<00:15, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  55% 5.51G/9.93G [00:14<00:15, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  56% 5.54G/9.93G [00:14<00:15, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  56% 5.57G/9.93G [00:14<00:15, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  56% 5.60G/9.93G [00:14<00:15, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  57% 5.64G/9.93G [00:14<00:13, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  57% 5.68G/9.93G [00:15<00:13, 312MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  58% 5.73G/9.93G [00:15<00:12, 335MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  58% 5.77G/9.93G [00:15<00:12, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  59% 5.81G/9.93G [00:15<00:11, 344MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  59% 5.85G/9.93G [00:15<00:11, 352MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  59% 5.90G/9.93G [00:15<00:10, 379MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  60% 5.96G/9.93G [00:15<00:15, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  60% 6.00G/9.93G [00:16<00:13, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  61% 6.04G/9.93G [00:16<00:13, 296MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  61% 6.08G/9.93G [00:16<00:12, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  62% 6.12G/9.93G [00:16<00:12, 316MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  62% 6.17G/9.93G [00:16<00:11, 336MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  63% 6.21G/9.93G [00:16<00:10, 351MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  63% 6.25G/9.93G [00:16<00:10, 362MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  63% 6.29G/9.93G [00:16<00:10, 357MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  64% 6.33G/9.93G [00:17<00:10, 352MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  64% 6.38G/9.93G [00:17<00:10, 353MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  65% 6.43G/9.93G [00:17<00:09, 378MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  65% 6.48G/9.93G [00:17<00:08, 407MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  66% 6.53G/9.93G [00:17<00:07, 429MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  66% 6.59G/9.93G [00:17<00:07, 448MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  67% 6.64G/9.93G [00:17<00:07, 415MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  67% 6.69G/9.93G [00:17<00:08, 365MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  68% 6.74G/9.93G [00:18<00:08, 395MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  68% 6.79G/9.93G [00:18<00:07, 420MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  69% 6.85G/9.93G [00:18<00:06, 440MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  70% 6.90G/9.93G [00:18<00:06, 457MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  70% 6.95G/9.93G [00:18<00:06, 469MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  71% 7.00G/9.93G [00:18<00:06, 479MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  71% 7.06G/9.93G [00:18<00:05, 487MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  72% 7.11G/9.93G [00:18<00:05, 491MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  72% 7.16G/9.93G [00:18<00:05, 494MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  73% 7.21G/9.93G [00:18<00:05, 495MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  73% 7.27G/9.93G [00:19<00:05, 452MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  74% 7.32G/9.93G [00:19<00:07, 354MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  74% 7.36G/9.93G [00:19<00:08, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  75% 7.40G/9.93G [00:19<00:09, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  75% 7.43G/9.93G [00:19<00:09, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  75% 7.47G/9.93G [00:19<00:09, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  76% 7.50G/9.93G [00:20<00:10, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  76% 7.53G/9.93G [00:20<00:09, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  76% 7.56G/9.93G [00:20<00:09, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  76% 7.59G/9.93G [00:20<00:10, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  77% 7.62G/9.93G [00:20<00:09, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  77% 7.65G/9.93G [00:20<00:09, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  77% 7.69G/9.93G [00:20<00:09, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  78% 7.73G/9.93G [00:21<00:08, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  78% 7.77G/9.93G [00:21<00:07, 292MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  79% 7.81G/9.93G [00:21<00:06, 312MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  79% 7.85G/9.93G [00:21<00:06, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  80% 7.91G/9.93G [00:21<00:05, 369MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  80% 7.96G/9.93G [00:21<00:04, 398MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  81% 8.01G/9.93G [00:21<00:04, 413MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  81% 8.06G/9.93G [00:21<00:04, 419MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  82% 8.12G/9.93G [00:21<00:04, 432MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  82% 8.17G/9.93G [00:22<00:03, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  83% 8.22G/9.93G [00:22<00:03, 452MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  83% 8.27G/9.93G [00:22<00:03, 468MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  84% 8.33G/9.93G [00:22<00:03, 480MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  84% 8.38G/9.93G [00:22<00:03, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  85% 8.43G/9.93G [00:22<00:03, 497MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  85% 8.48G/9.93G [00:22<00:02, 500MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  86% 8.54G/9.93G [00:22<00:02, 488MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  87% 8.59G/9.93G [00:22<00:02, 490MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  87% 8.64G/9.93G [00:23<00:02, 470MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  88% 8.69G/9.93G [00:23<00:02, 431MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  88% 8.75G/9.93G [00:23<00:02, 394MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  89% 8.79G/9.93G [00:23<00:02, 381MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  89% 8.83G/9.93G [00:23<00:03, 362MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  89% 8.87G/9.93G [00:23<00:03, 346MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  90% 8.91G/9.93G [00:23<00:03, 329MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  90% 8.95G/9.93G [00:24<00:03, 322MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  91% 9.00G/9.93G [00:24<00:03, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  91% 9.03G/9.93G [00:24<00:03, 296MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  91% 9.06G/9.93G [00:24<00:02, 293MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  92% 9.09G/9.93G [00:24<00:02, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  92% 9.12G/9.93G [00:24<00:02, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  92% 9.15G/9.93G [00:24<00:02, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  93% 9.19G/9.93G [00:24<00:02, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  93% 9.22G/9.93G [00:25<00:02, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  93% 9.25G/9.93G [00:25<00:02, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  93% 9.28G/9.93G [00:25<00:02, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  94% 9.31G/9.93G [00:25<00:02, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  94% 9.34G/9.93G [00:25<00:02, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  94% 9.37G/9.93G [00:25<00:02, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  95% 9.41G/9.93G [00:25<00:02, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  95% 9.44G/9.93G [00:26<00:02, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  95% 9.47G/9.93G [00:26<00:02, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  96% 9.50G/9.93G [00:26<00:01, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  96% 9.54G/9.93G [00:26<00:01, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  97% 9.59G/9.93G [00:26<00:01, 327MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  97% 9.65G/9.93G [00:26<00:00, 363MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  98% 9.70G/9.93G [00:26<00:00, 390MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  98% 9.75G/9.93G [00:26<00:00, 412MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  99% 9.80G/9.93G [00:26<00:00, 428MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin:  99% 9.86G/9.93G [00:27<00:00, 443MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00002.bin: 100% 9.93G/9.93G [00:27<00:00, 365MB/s]\n",
            "Downloading shards:  50% 1/2 [00:30<00:30, 30.71s/it]\n",
            "Downloading (…)l-00002-of-00002.bin:   0% 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   1% 52.4M/3.95G [00:00<00:08, 471MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   3% 105M/3.95G [00:00<00:07, 488MB/s] \u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   4% 157M/3.95G [00:00<00:07, 493MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   5% 210M/3.95G [00:00<00:07, 496MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   7% 262M/3.95G [00:00<00:07, 495MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   8% 315M/3.95G [00:00<00:07, 496MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:   9% 367M/3.95G [00:00<00:07, 493MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  11% 419M/3.95G [00:00<00:07, 502MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  12% 482M/3.95G [00:00<00:06, 509MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  14% 535M/3.95G [00:01<00:06, 511MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  15% 587M/3.95G [00:01<00:06, 512MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  16% 640M/3.95G [00:01<00:10, 317MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  17% 682M/3.95G [00:01<00:09, 330MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  18% 724M/3.95G [00:01<00:09, 334MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  19% 765M/3.95G [00:01<00:09, 349MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  21% 818M/3.95G [00:01<00:08, 391MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  22% 870M/3.95G [00:02<00:07, 423MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  23% 923M/3.95G [00:02<00:06, 446MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  25% 975M/3.95G [00:02<00:06, 462MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  26% 1.04G/3.95G [00:02<00:06, 485MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  28% 1.10G/3.95G [00:02<00:05, 499MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  29% 1.16G/3.95G [00:02<00:05, 507MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  31% 1.22G/3.95G [00:02<00:05, 504MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  32% 1.27G/3.95G [00:02<00:05, 503MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  33% 1.32G/3.95G [00:02<00:05, 499MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  35% 1.37G/3.95G [00:03<00:05, 495MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  36% 1.43G/3.95G [00:03<00:05, 493MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  37% 1.48G/3.95G [00:03<00:05, 492MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  39% 1.53G/3.95G [00:03<00:04, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  40% 1.58G/3.95G [00:03<00:04, 488MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  41% 1.64G/3.95G [00:03<00:04, 487MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  43% 1.69G/3.95G [00:03<00:04, 489MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  44% 1.74G/3.95G [00:03<00:04, 491MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  45% 1.79G/3.95G [00:03<00:04, 490MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  47% 1.85G/3.95G [00:04<00:04, 464MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  48% 1.90G/3.95G [00:04<00:04, 431MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  49% 1.95G/3.95G [00:04<00:05, 383MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  50% 1.99G/3.95G [00:04<00:05, 384MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  52% 2.04G/3.95G [00:04<00:04, 405MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  53% 2.10G/3.95G [00:04<00:04, 420MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  54% 2.15G/3.95G [00:04<00:04, 432MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  56% 2.20G/3.95G [00:04<00:04, 436MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  57% 2.25G/3.95G [00:05<00:03, 433MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  58% 2.31G/3.95G [00:05<00:03, 439MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  60% 2.36G/3.95G [00:05<00:03, 448MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  61% 2.41G/3.95G [00:05<00:03, 457MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  62% 2.46G/3.95G [00:05<00:03, 458MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  64% 2.52G/3.95G [00:05<00:03, 444MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  65% 2.57G/3.95G [00:05<00:03, 450MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  66% 2.62G/3.95G [00:05<00:03, 443MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  68% 2.67G/3.95G [00:05<00:02, 447MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  69% 2.73G/3.95G [00:06<00:02, 447MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  70% 2.78G/3.95G [00:06<00:02, 449MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  72% 2.83G/3.95G [00:06<00:02, 446MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  73% 2.88G/3.95G [00:06<00:02, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  74% 2.94G/3.95G [00:06<00:02, 444MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  76% 2.99G/3.95G [00:06<00:02, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  77% 3.04G/3.95G [00:06<00:02, 438MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  78% 3.09G/3.95G [00:06<00:01, 440MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  80% 3.15G/3.95G [00:07<00:01, 442MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  81% 3.20G/3.95G [00:07<00:01, 440MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  82% 3.25G/3.95G [00:07<00:01, 442MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  84% 3.30G/3.95G [00:07<00:01, 446MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  85% 3.36G/3.95G [00:07<00:01, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  86% 3.41G/3.95G [00:07<00:01, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  88% 3.46G/3.95G [00:07<00:01, 448MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  89% 3.51G/3.95G [00:07<00:00, 446MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  90% 3.57G/3.95G [00:07<00:00, 442MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  92% 3.62G/3.95G [00:08<00:00, 440MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  93% 3.67G/3.95G [00:08<00:00, 445MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  94% 3.72G/3.95G [00:08<00:00, 438MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  96% 3.77G/3.95G [00:08<00:00, 438MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  97% 3.83G/3.95G [00:08<00:00, 438MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin:  98% 3.88G/3.95G [00:08<00:00, 431MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00002.bin: 100% 3.95G/3.95G [00:08<00:00, 444MB/s]\n",
            "Downloading shards: 100% 2/2 [00:39<00:00, 19.93s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:11<00:00,  5.67s/it]\n",
            "Downloading (…)neration_config.json: 100% 116/116 [00:00<00:00, 585kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 323/323 [00:00<00:00, 1.76MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 3.23M/3.23M [00:01<00:00, 3.06MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 129/129 [00:00<00:00, 652kB/s]\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-ea90af88aef6d368/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 2347.12it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 186.25it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-ea90af88aef6d368/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 616.27it/s]\n",
            "trainable params: 4194304 || all params: 6876176384 || trainable%: 0.06099762085451472\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/work/lora-instruct/wandb/run-20230517_160140-g1mya3sp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-elevator-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/zuruzirou/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/zuruzirou/huggingface/runs/g1mya3sp\u001b[0m\n",
            "  2% 9/420 [01:12<53:16,  7.78s/it]こんにちは、\n",
            "{'loss': 2.4783, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.07}\n",
            "  2% 10/420 [01:20<53:04,  7.77s/it]こんにちは、じこ紹介\n",
            "  3% 14/420 [01:50<51:48,  7.66s/it]自己紹介\n",
            "自己紹介\n",
            "{'loss': 2.4527, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.14}\n",
            "{'loss': 2.323, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.21}\n",
            "{'loss': 1.9755, 'learning_rate': 0.00011999999999999999, 'epoch': 0.28}\n",
            "{'loss': 1.4913, 'learning_rate': 0.00015, 'epoch': 0.36}\n",
            "{'loss': 1.2124, 'learning_rate': 0.00017999999999999998, 'epoch': 0.43}\n",
            "{'loss': 1.1576, 'learning_rate': 0.00020999999999999998, 'epoch': 0.5}\n",
            "{'loss': 1.1204, 'learning_rate': 0.00023999999999999998, 'epoch': 0.57}\n",
            "{'loss': 1.0728, 'learning_rate': 0.00027, 'epoch': 0.64}\n",
            "{'loss': 1.0425, 'learning_rate': 0.0003, 'epoch': 0.71}\n",
            "{'loss': 1.0234, 'learning_rate': 0.000290625, 'epoch': 0.78}\n",
            "{'loss': 0.998, 'learning_rate': 0.00028125, 'epoch': 0.85}\n",
            "{'loss': 0.9765, 'learning_rate': 0.000271875, 'epoch': 0.92}\n",
            "{'loss': 0.9873, 'learning_rate': 0.0002625, 'epoch': 0.99}\n",
            "{'loss': 0.9462, 'learning_rate': 0.000253125, 'epoch': 1.07}\n",
            "{'loss': 0.9432, 'learning_rate': 0.00024375, 'epoch': 1.14}\n",
            "{'loss': 0.919, 'learning_rate': 0.000234375, 'epoch': 1.21}\n",
            "{'loss': 0.9133, 'learning_rate': 0.000225, 'epoch': 1.28}\n",
            "{'loss': 0.921, 'learning_rate': 0.00021562499999999997, 'epoch': 1.35}\n",
            "{'loss': 0.9076, 'learning_rate': 0.00020624999999999997, 'epoch': 1.42}\n",
            " 48% 200/420 [25:37<28:36,  7.80s/it]\n",
            "  0% 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/250 [00:00<00:24, 10.16it/s]\u001b[A\n",
            "  2% 4/250 [00:00<00:39,  6.16it/s]\u001b[A\n",
            "  2% 5/250 [00:00<00:43,  5.63it/s]\u001b[A\n",
            "  2% 6/250 [00:01<00:46,  5.30it/s]\u001b[A\n",
            "  3% 7/250 [00:01<00:47,  5.09it/s]\u001b[A\n",
            "  3% 8/250 [00:01<00:48,  4.95it/s]\u001b[A\n",
            "  4% 9/250 [00:01<00:49,  4.86it/s]\u001b[A\n",
            "  4% 10/250 [00:01<00:50,  4.80it/s]\u001b[A\n",
            "  4% 11/250 [00:02<00:49,  4.84it/s]\u001b[A\n",
            "  5% 12/250 [00:02<00:48,  4.95it/s]\u001b[A\n",
            "  5% 13/250 [00:02<00:48,  4.86it/s]\u001b[A\n",
            "  6% 14/250 [00:02<00:49,  4.80it/s]\u001b[A\n",
            "  6% 15/250 [00:02<00:49,  4.75it/s]\u001b[A\n",
            "  6% 16/250 [00:03<00:46,  5.06it/s]\u001b[A\n",
            "  7% 17/250 [00:03<00:42,  5.46it/s]\u001b[A\n",
            "  7% 18/250 [00:03<00:44,  5.21it/s]\u001b[A\n",
            "  8% 19/250 [00:03<00:44,  5.20it/s]\u001b[A\n",
            "  8% 20/250 [00:03<00:45,  5.03it/s]\u001b[A\n",
            "  8% 21/250 [00:04<00:46,  4.91it/s]\u001b[A\n",
            "  9% 22/250 [00:04<00:47,  4.83it/s]\u001b[A\n",
            "  9% 23/250 [00:04<00:43,  5.23it/s]\u001b[A\n",
            " 10% 24/250 [00:04<00:44,  5.06it/s]\u001b[A\n",
            " 10% 25/250 [00:04<00:41,  5.41it/s]\u001b[A\n",
            " 10% 26/250 [00:05<00:43,  5.18it/s]\u001b[A\n",
            " 11% 27/250 [00:05<00:44,  5.01it/s]\u001b[A\n",
            " 11% 28/250 [00:05<00:41,  5.37it/s]\u001b[A\n",
            " 12% 29/250 [00:05<00:42,  5.17it/s]\u001b[A\n",
            " 12% 30/250 [00:05<00:43,  5.01it/s]\u001b[A\n",
            " 12% 31/250 [00:06<00:44,  4.90it/s]\u001b[A\n",
            " 13% 32/250 [00:06<00:45,  4.82it/s]\u001b[A\n",
            " 13% 33/250 [00:06<00:45,  4.77it/s]\u001b[A\n",
            " 14% 34/250 [00:06<00:45,  4.73it/s]\u001b[A\n",
            " 14% 35/250 [00:06<00:44,  4.82it/s]\u001b[A\n",
            " 14% 36/250 [00:07<00:44,  4.78it/s]\u001b[A\n",
            " 15% 37/250 [00:07<00:44,  4.73it/s]\u001b[A\n",
            " 15% 38/250 [00:07<00:45,  4.70it/s]\u001b[A\n",
            " 16% 39/250 [00:07<00:45,  4.69it/s]\u001b[A\n",
            " 16% 40/250 [00:07<00:44,  4.68it/s]\u001b[A\n",
            " 16% 41/250 [00:08<00:43,  4.79it/s]\u001b[A\n",
            " 17% 42/250 [00:08<00:43,  4.76it/s]\u001b[A\n",
            " 17% 43/250 [00:08<00:43,  4.72it/s]\u001b[A\n",
            " 18% 44/250 [00:08<00:43,  4.70it/s]\u001b[A\n",
            " 18% 45/250 [00:09<00:43,  4.68it/s]\u001b[A\n",
            " 18% 46/250 [00:09<00:43,  4.67it/s]\u001b[A\n",
            " 19% 47/250 [00:09<00:43,  4.67it/s]\u001b[A\n",
            " 19% 48/250 [00:09<00:43,  4.65it/s]\u001b[A\n",
            " 20% 49/250 [00:09<00:43,  4.65it/s]\u001b[A\n",
            " 20% 50/250 [00:10<00:42,  4.65it/s]\u001b[A\n",
            " 20% 51/250 [00:10<00:42,  4.65it/s]\u001b[A\n",
            " 21% 52/250 [00:10<00:42,  4.66it/s]\u001b[A\n",
            " 21% 53/250 [00:10<00:42,  4.66it/s]\u001b[A\n",
            " 22% 54/250 [00:10<00:40,  4.80it/s]\u001b[A\n",
            " 22% 55/250 [00:11<00:40,  4.87it/s]\u001b[A\n",
            " 22% 56/250 [00:11<00:40,  4.81it/s]\u001b[A\n",
            " 23% 57/250 [00:11<00:40,  4.76it/s]\u001b[A\n",
            " 23% 58/250 [00:11<00:40,  4.73it/s]\u001b[A\n",
            " 24% 59/250 [00:11<00:39,  4.86it/s]\u001b[A\n",
            " 24% 60/250 [00:12<00:39,  4.80it/s]\u001b[A\n",
            " 24% 61/250 [00:12<00:39,  4.76it/s]\u001b[A\n",
            " 25% 62/250 [00:12<00:38,  4.84it/s]\u001b[A\n",
            " 25% 63/250 [00:12<00:39,  4.79it/s]\u001b[A\n",
            " 26% 64/250 [00:13<00:39,  4.75it/s]\u001b[A\n",
            " 26% 65/250 [00:13<00:39,  4.72it/s]\u001b[A\n",
            " 26% 66/250 [00:13<00:39,  4.70it/s]\u001b[A\n",
            " 27% 67/250 [00:13<00:36,  5.02it/s]\u001b[A\n",
            " 27% 68/250 [00:13<00:36,  4.92it/s]\u001b[A\n",
            " 28% 69/250 [00:14<00:37,  4.84it/s]\u001b[A\n",
            " 28% 70/250 [00:14<00:34,  5.23it/s]\u001b[A\n",
            " 28% 71/250 [00:14<00:34,  5.21it/s]\u001b[A\n",
            " 29% 72/250 [00:14<00:34,  5.17it/s]\u001b[A\n",
            " 29% 73/250 [00:14<00:35,  5.01it/s]\u001b[A\n",
            " 30% 74/250 [00:15<00:35,  4.90it/s]\u001b[A\n",
            " 30% 75/250 [00:15<00:36,  4.82it/s]\u001b[A\n",
            " 30% 76/250 [00:15<00:36,  4.77it/s]\u001b[A\n",
            " 31% 77/250 [00:15<00:36,  4.74it/s]\u001b[A\n",
            " 31% 78/250 [00:15<00:36,  4.71it/s]\u001b[A\n",
            " 32% 79/250 [00:16<00:36,  4.69it/s]\u001b[A\n",
            " 32% 80/250 [00:16<00:36,  4.68it/s]\u001b[A\n",
            " 32% 81/250 [00:16<00:36,  4.67it/s]\u001b[A\n",
            " 33% 82/250 [00:16<00:35,  4.67it/s]\u001b[A\n",
            " 33% 83/250 [00:16<00:35,  4.67it/s]\u001b[A\n",
            " 34% 84/250 [00:17<00:35,  4.66it/s]\u001b[A\n",
            " 34% 85/250 [00:17<00:34,  4.77it/s]\u001b[A\n",
            " 34% 86/250 [00:17<00:32,  5.06it/s]\u001b[A\n",
            " 35% 87/250 [00:17<00:32,  4.94it/s]\u001b[A\n",
            " 35% 88/250 [00:17<00:33,  4.86it/s]\u001b[A\n",
            " 36% 89/250 [00:18<00:33,  4.79it/s]\u001b[A\n",
            " 36% 90/250 [00:18<00:33,  4.75it/s]\u001b[A\n",
            " 36% 91/250 [00:18<00:33,  4.81it/s]\u001b[A\n",
            " 37% 92/250 [00:18<00:33,  4.77it/s]\u001b[A\n",
            " 37% 93/250 [00:19<00:33,  4.73it/s]\u001b[A\n",
            " 38% 94/250 [00:19<00:33,  4.71it/s]\u001b[A\n",
            " 38% 95/250 [00:19<00:31,  4.95it/s]\u001b[A\n",
            " 38% 96/250 [00:19<00:31,  4.87it/s]\u001b[A\n",
            " 39% 97/250 [00:19<00:31,  4.90it/s]\u001b[A\n",
            " 39% 98/250 [00:20<00:30,  4.92it/s]\u001b[A\n",
            " 40% 99/250 [00:20<00:31,  4.84it/s]\u001b[A\n",
            " 40% 100/250 [00:20<00:31,  4.78it/s]\u001b[A\n",
            " 40% 101/250 [00:20<00:31,  4.75it/s]\u001b[A\n",
            " 41% 102/250 [00:20<00:31,  4.72it/s]\u001b[A\n",
            " 41% 103/250 [00:21<00:31,  4.70it/s]\u001b[A\n",
            " 42% 104/250 [00:21<00:31,  4.69it/s]\u001b[A\n",
            " 42% 105/250 [00:21<00:30,  4.69it/s]\u001b[A\n",
            " 42% 106/250 [00:21<00:30,  4.67it/s]\u001b[A\n",
            " 43% 107/250 [00:21<00:30,  4.67it/s]\u001b[A\n",
            " 43% 108/250 [00:22<00:30,  4.66it/s]\u001b[A\n",
            " 44% 109/250 [00:22<00:30,  4.66it/s]\u001b[A\n",
            " 44% 110/250 [00:22<00:29,  4.76it/s]\u001b[A\n",
            " 44% 111/250 [00:22<00:29,  4.73it/s]\u001b[A\n",
            " 45% 112/250 [00:23<00:28,  4.80it/s]\u001b[A\n",
            " 45% 113/250 [00:23<00:27,  5.02it/s]\u001b[A\n",
            " 46% 114/250 [00:23<00:27,  4.92it/s]\u001b[A\n",
            " 46% 115/250 [00:23<00:27,  4.82it/s]\u001b[A\n",
            " 46% 116/250 [00:23<00:28,  4.76it/s]\u001b[A\n",
            " 47% 117/250 [00:24<00:28,  4.71it/s]\u001b[A\n",
            " 47% 118/250 [00:24<00:28,  4.70it/s]\u001b[A\n",
            " 48% 119/250 [00:24<00:27,  4.83it/s]\u001b[A\n",
            " 48% 120/250 [00:24<00:27,  4.79it/s]\u001b[A\n",
            " 48% 121/250 [00:24<00:27,  4.75it/s]\u001b[A\n",
            " 49% 122/250 [00:25<00:24,  5.26it/s]\u001b[A\n",
            " 49% 123/250 [00:25<00:25,  5.07it/s]\u001b[A\n",
            " 50% 124/250 [00:25<00:24,  5.11it/s]\u001b[A\n",
            " 50% 125/250 [00:25<00:25,  4.97it/s]\u001b[A\n",
            " 50% 126/250 [00:25<00:25,  4.87it/s]\u001b[A\n",
            " 51% 127/250 [00:26<00:23,  5.13it/s]\u001b[A\n",
            " 51% 128/250 [00:26<00:24,  4.99it/s]\u001b[A\n",
            " 52% 129/250 [00:26<00:24,  4.89it/s]\u001b[A\n",
            " 52% 130/250 [00:26<00:24,  4.81it/s]\u001b[A\n",
            " 52% 131/250 [00:26<00:24,  4.88it/s]\u001b[A\n",
            " 53% 132/250 [00:27<00:24,  4.82it/s]\u001b[A\n",
            " 53% 133/250 [00:27<00:24,  4.77it/s]\u001b[A\n",
            " 54% 134/250 [00:27<00:24,  4.73it/s]\u001b[A\n",
            " 54% 135/250 [00:27<00:23,  4.81it/s]\u001b[A\n",
            " 54% 136/250 [00:27<00:22,  5.04it/s]\u001b[A\n",
            " 55% 137/250 [00:28<00:22,  4.93it/s]\u001b[A\n",
            " 55% 138/250 [00:28<00:23,  4.85it/s]\u001b[A\n",
            " 56% 139/250 [00:28<00:23,  4.79it/s]\u001b[A\n",
            " 56% 140/250 [00:28<00:23,  4.75it/s]\u001b[A\n",
            " 56% 141/250 [00:28<00:23,  4.72it/s]\u001b[A\n",
            " 57% 142/250 [00:29<00:22,  4.70it/s]\u001b[A\n",
            " 57% 143/250 [00:29<00:22,  4.69it/s]\u001b[A\n",
            " 58% 144/250 [00:29<00:22,  4.67it/s]\u001b[A\n",
            " 58% 145/250 [00:29<00:22,  4.69it/s]\u001b[A\n",
            " 58% 146/250 [00:29<00:20,  5.01it/s]\u001b[A\n",
            " 59% 147/250 [00:30<00:20,  4.91it/s]\u001b[A\n",
            " 59% 148/250 [00:30<00:21,  4.83it/s]\u001b[A\n",
            " 60% 149/250 [00:30<00:21,  4.78it/s]\u001b[A\n",
            " 60% 150/250 [00:30<00:21,  4.74it/s]\u001b[A\n",
            " 60% 151/250 [00:31<00:21,  4.71it/s]\u001b[A\n",
            " 61% 152/250 [00:31<00:20,  4.81it/s]\u001b[A\n",
            " 61% 153/250 [00:31<00:20,  4.76it/s]\u001b[A\n",
            " 62% 154/250 [00:31<00:19,  4.86it/s]\u001b[A\n",
            " 62% 155/250 [00:31<00:19,  4.80it/s]\u001b[A\n",
            " 62% 156/250 [00:32<00:19,  4.75it/s]\u001b[A\n",
            " 63% 157/250 [00:32<00:19,  4.72it/s]\u001b[A\n",
            " 63% 158/250 [00:32<00:19,  4.72it/s]\u001b[A\n",
            " 64% 159/250 [00:32<00:19,  4.70it/s]\u001b[A\n",
            " 64% 160/250 [00:32<00:19,  4.68it/s]\u001b[A\n",
            " 64% 161/250 [00:33<00:18,  4.76it/s]\u001b[A\n",
            " 65% 162/250 [00:33<00:18,  4.73it/s]\u001b[A\n",
            " 65% 163/250 [00:33<00:18,  4.72it/s]\u001b[A\n",
            " 66% 164/250 [00:33<00:17,  4.82it/s]\u001b[A\n",
            " 66% 165/250 [00:34<00:17,  4.78it/s]\u001b[A\n",
            " 66% 166/250 [00:34<00:17,  4.74it/s]\u001b[A\n",
            " 67% 167/250 [00:34<00:17,  4.84it/s]\u001b[A\n",
            " 67% 168/250 [00:34<00:17,  4.79it/s]\u001b[A\n",
            " 68% 169/250 [00:34<00:17,  4.75it/s]\u001b[A\n",
            " 68% 170/250 [00:35<00:16,  4.72it/s]\u001b[A\n",
            " 68% 171/250 [00:35<00:16,  4.70it/s]\u001b[A\n",
            " 69% 172/250 [00:35<00:16,  4.69it/s]\u001b[A\n",
            " 69% 173/250 [00:35<00:16,  4.68it/s]\u001b[A\n",
            " 70% 174/250 [00:35<00:15,  4.76it/s]\u001b[A\n",
            " 70% 175/250 [00:36<00:15,  4.73it/s]\u001b[A\n",
            " 70% 176/250 [00:36<00:15,  4.70it/s]\u001b[A\n",
            " 71% 177/250 [00:36<00:15,  4.68it/s]\u001b[A\n",
            " 71% 178/250 [00:36<00:15,  4.67it/s]\u001b[A\n",
            " 72% 179/250 [00:36<00:15,  4.67it/s]\u001b[A\n",
            " 72% 180/250 [00:37<00:15,  4.67it/s]\u001b[A\n",
            " 72% 181/250 [00:37<00:14,  4.66it/s]\u001b[A\n",
            " 73% 182/250 [00:37<00:14,  4.65it/s]\u001b[A\n",
            " 73% 183/250 [00:37<00:14,  4.64it/s]\u001b[A\n",
            " 74% 184/250 [00:38<00:14,  4.65it/s]\u001b[A\n",
            " 74% 185/250 [00:38<00:13,  4.65it/s]\u001b[A\n",
            " 74% 186/250 [00:38<00:13,  4.65it/s]\u001b[A\n",
            " 75% 187/250 [00:38<00:12,  5.08it/s]\u001b[A\n",
            " 75% 188/250 [00:38<00:11,  5.28it/s]\u001b[A\n",
            " 76% 189/250 [00:39<00:11,  5.09it/s]\u001b[A\n",
            " 76% 190/250 [00:39<00:11,  5.06it/s]\u001b[A\n",
            " 76% 191/250 [00:39<00:11,  5.24it/s]\u001b[A\n",
            " 77% 192/250 [00:39<00:10,  5.39it/s]\u001b[A\n",
            " 77% 193/250 [00:39<00:11,  5.16it/s]\u001b[A\n",
            " 78% 194/250 [00:40<00:11,  5.00it/s]\u001b[A\n",
            " 78% 195/250 [00:40<00:10,  5.06it/s]\u001b[A\n",
            " 78% 196/250 [00:40<00:10,  4.94it/s]\u001b[A\n",
            " 79% 197/250 [00:40<00:10,  4.86it/s]\u001b[A\n",
            " 79% 198/250 [00:40<00:10,  4.81it/s]\u001b[A\n",
            " 80% 199/250 [00:41<00:10,  4.77it/s]\u001b[A\n",
            " 80% 200/250 [00:41<00:10,  4.73it/s]\u001b[A\n",
            " 80% 201/250 [00:41<00:10,  4.71it/s]\u001b[A\n",
            " 81% 202/250 [00:41<00:10,  4.79it/s]\u001b[A\n",
            " 81% 203/250 [00:41<00:09,  4.76it/s]\u001b[A\n",
            " 82% 204/250 [00:42<00:09,  4.73it/s]\u001b[A\n",
            " 82% 205/250 [00:42<00:09,  4.71it/s]\u001b[A\n",
            " 82% 206/250 [00:42<00:09,  4.82it/s]\u001b[A\n",
            " 83% 207/250 [00:42<00:09,  4.78it/s]\u001b[A\n",
            " 83% 208/250 [00:42<00:08,  4.74it/s]\u001b[A\n",
            " 84% 209/250 [00:43<00:08,  4.71it/s]\u001b[A\n",
            " 84% 210/250 [00:43<00:08,  4.70it/s]\u001b[A\n",
            " 84% 211/250 [00:43<00:08,  4.68it/s]\u001b[A\n",
            " 85% 212/250 [00:43<00:08,  4.67it/s]\u001b[A\n",
            " 85% 213/250 [00:44<00:07,  4.67it/s]\u001b[A\n",
            " 86% 214/250 [00:44<00:07,  4.66it/s]\u001b[A\n",
            " 86% 215/250 [00:44<00:07,  4.66it/s]\u001b[A\n",
            " 86% 216/250 [00:44<00:07,  4.81it/s]\u001b[A\n",
            " 87% 217/250 [00:44<00:06,  4.77it/s]\u001b[A\n",
            " 87% 218/250 [00:45<00:06,  4.73it/s]\u001b[A\n",
            " 88% 219/250 [00:45<00:06,  4.71it/s]\u001b[A\n",
            " 88% 220/250 [00:45<00:06,  4.80it/s]\u001b[A\n",
            " 88% 221/250 [00:45<00:06,  4.75it/s]\u001b[A\n",
            " 89% 222/250 [00:45<00:05,  4.72it/s]\u001b[A\n",
            " 89% 223/250 [00:46<00:05,  4.98it/s]\u001b[A\n",
            " 90% 224/250 [00:46<00:05,  4.91it/s]\u001b[A\n",
            " 90% 225/250 [00:46<00:05,  4.83it/s]\u001b[A\n",
            " 90% 226/250 [00:46<00:05,  4.77it/s]\u001b[A\n",
            " 91% 227/250 [00:46<00:04,  4.74it/s]\u001b[A\n",
            " 91% 228/250 [00:47<00:04,  4.71it/s]\u001b[A\n",
            " 92% 229/250 [00:47<00:04,  4.69it/s]\u001b[A\n",
            " 92% 230/250 [00:47<00:04,  4.67it/s]\u001b[A\n",
            " 92% 231/250 [00:47<00:04,  4.65it/s]\u001b[A\n",
            " 93% 232/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 93% 233/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 94% 234/250 [00:48<00:03,  4.65it/s]\u001b[A\n",
            " 94% 235/250 [00:48<00:03,  4.65it/s]\u001b[A\n",
            " 94% 236/250 [00:48<00:03,  4.65it/s]\u001b[A\n",
            " 95% 237/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 95% 238/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 239/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 240/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 241/250 [00:49<00:01,  4.65it/s]\u001b[A\n",
            " 97% 242/250 [00:50<00:01,  4.65it/s]\u001b[A\n",
            " 97% 243/250 [00:50<00:01,  4.65it/s]\u001b[A\n",
            " 98% 244/250 [00:50<00:01,  4.66it/s]\u001b[A\n",
            " 98% 245/250 [00:50<00:01,  4.93it/s]\u001b[A\n",
            " 98% 246/250 [00:50<00:00,  4.99it/s]\u001b[A\n",
            " 99% 247/250 [00:51<00:00,  4.89it/s]\u001b[A\n",
            " 99% 248/250 [00:51<00:00,  4.82it/s]\u001b[A\n",
            "100% 249/250 [00:51<00:00,  4.90it/s]\u001b[A\n",
            "100% 250/250 [00:51<00:00,  4.83it/s]\u001b[A\n",
            "{'eval_loss': 0.9140862822532654, 'eval_runtime': 52.0331, 'eval_samples_per_second': 38.437, 'eval_steps_per_second': 4.805, 'epoch': 1.42}\n",
            "\n",
            " 48% 200/420 [26:29<28:36,  7.80s/it]\n",
            "{'loss': 0.8855, 'learning_rate': 0.00019687499999999997, 'epoch': 1.49}\n",
            "{'loss': 0.8778, 'learning_rate': 0.00018749999999999998, 'epoch': 1.56}\n",
            "{'loss': 0.8754, 'learning_rate': 0.00017812499999999998, 'epoch': 1.63}\n",
            "{'loss': 0.8764, 'learning_rate': 0.00016874999999999998, 'epoch': 1.7}\n",
            "{'loss': 0.8707, 'learning_rate': 0.00015937499999999998, 'epoch': 1.78}\n",
            "{'loss': 0.8509, 'learning_rate': 0.00015, 'epoch': 1.85}\n",
            "{'loss': 0.8591, 'learning_rate': 0.000140625, 'epoch': 1.92}\n",
            "{'loss': 0.8562, 'learning_rate': 0.00013125, 'epoch': 1.99}\n",
            "{'loss': 0.8562, 'learning_rate': 0.000121875, 'epoch': 2.06}\n",
            "{'loss': 0.8352, 'learning_rate': 0.0001125, 'epoch': 2.13}\n",
            "{'loss': 0.8329, 'learning_rate': 0.00010312499999999999, 'epoch': 2.2}\n",
            "{'loss': 0.8365, 'learning_rate': 9.374999999999999e-05, 'epoch': 2.27}\n",
            "{'loss': 0.8232, 'learning_rate': 8.437499999999999e-05, 'epoch': 2.34}\n",
            "{'loss': 0.8395, 'learning_rate': 7.5e-05, 'epoch': 2.41}\n",
            "{'loss': 0.8272, 'learning_rate': 6.5625e-05, 'epoch': 2.49}\n",
            "{'loss': 0.8257, 'learning_rate': 5.625e-05, 'epoch': 2.56}\n",
            "{'loss': 0.8363, 'learning_rate': 4.6874999999999994e-05, 'epoch': 2.63}\n",
            "{'loss': 0.8154, 'learning_rate': 3.75e-05, 'epoch': 2.7}\n",
            "{'loss': 0.8106, 'learning_rate': 2.8125e-05, 'epoch': 2.77}\n",
            "{'loss': 0.8274, 'learning_rate': 1.875e-05, 'epoch': 2.84}\n",
            " 95% 400/420 [52:03<02:34,  7.71s/it]\n",
            "  0% 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/250 [00:00<00:24, 10.09it/s]\u001b[A\n",
            "  2% 4/250 [00:00<00:39,  6.17it/s]\u001b[A\n",
            "  2% 5/250 [00:00<00:43,  5.64it/s]\u001b[A\n",
            "  2% 6/250 [00:01<00:45,  5.31it/s]\u001b[A\n",
            "  3% 7/250 [00:01<00:47,  5.09it/s]\u001b[A\n",
            "  3% 8/250 [00:01<00:48,  4.96it/s]\u001b[A\n",
            "  4% 9/250 [00:01<00:49,  4.86it/s]\u001b[A\n",
            "  4% 10/250 [00:01<00:50,  4.80it/s]\u001b[A\n",
            "  4% 11/250 [00:02<00:49,  4.84it/s]\u001b[A\n",
            "  5% 12/250 [00:02<00:48,  4.94it/s]\u001b[A\n",
            "  5% 13/250 [00:02<00:48,  4.86it/s]\u001b[A\n",
            "  6% 14/250 [00:02<00:49,  4.79it/s]\u001b[A\n",
            "  6% 15/250 [00:02<00:49,  4.75it/s]\u001b[A\n",
            "  6% 16/250 [00:03<00:46,  5.06it/s]\u001b[A\n",
            "  7% 17/250 [00:03<00:42,  5.46it/s]\u001b[A\n",
            "  7% 18/250 [00:03<00:44,  5.21it/s]\u001b[A\n",
            "  8% 19/250 [00:03<00:44,  5.20it/s]\u001b[A\n",
            "  8% 20/250 [00:03<00:45,  5.03it/s]\u001b[A\n",
            "  8% 21/250 [00:04<00:46,  4.91it/s]\u001b[A\n",
            "  9% 22/250 [00:04<00:47,  4.83it/s]\u001b[A\n",
            "  9% 23/250 [00:04<00:43,  5.23it/s]\u001b[A\n",
            " 10% 24/250 [00:04<00:44,  5.06it/s]\u001b[A\n",
            " 10% 25/250 [00:04<00:41,  5.41it/s]\u001b[A\n",
            " 10% 26/250 [00:05<00:43,  5.18it/s]\u001b[A\n",
            " 11% 27/250 [00:05<00:44,  5.01it/s]\u001b[A\n",
            " 11% 28/250 [00:05<00:41,  5.38it/s]\u001b[A\n",
            " 12% 29/250 [00:05<00:42,  5.18it/s]\u001b[A\n",
            " 12% 30/250 [00:05<00:43,  5.01it/s]\u001b[A\n",
            " 12% 31/250 [00:06<00:44,  4.90it/s]\u001b[A\n",
            " 13% 32/250 [00:06<00:45,  4.83it/s]\u001b[A\n",
            " 13% 33/250 [00:06<00:45,  4.77it/s]\u001b[A\n",
            " 14% 34/250 [00:06<00:45,  4.73it/s]\u001b[A\n",
            " 14% 35/250 [00:06<00:44,  4.82it/s]\u001b[A\n",
            " 14% 36/250 [00:07<00:44,  4.78it/s]\u001b[A\n",
            " 15% 37/250 [00:07<00:44,  4.74it/s]\u001b[A\n",
            " 15% 38/250 [00:07<00:45,  4.71it/s]\u001b[A\n",
            " 16% 39/250 [00:07<00:44,  4.69it/s]\u001b[A\n",
            " 16% 40/250 [00:07<00:44,  4.68it/s]\u001b[A\n",
            " 16% 41/250 [00:08<00:43,  4.79it/s]\u001b[A\n",
            " 17% 42/250 [00:08<00:43,  4.76it/s]\u001b[A\n",
            " 17% 43/250 [00:08<00:43,  4.73it/s]\u001b[A\n",
            " 18% 44/250 [00:08<00:43,  4.70it/s]\u001b[A\n",
            " 18% 45/250 [00:09<00:43,  4.68it/s]\u001b[A\n",
            " 18% 46/250 [00:09<00:43,  4.67it/s]\u001b[A\n",
            " 19% 47/250 [00:09<00:43,  4.66it/s]\u001b[A\n",
            " 19% 48/250 [00:09<00:43,  4.66it/s]\u001b[A\n",
            " 20% 49/250 [00:09<00:43,  4.66it/s]\u001b[A\n",
            " 20% 50/250 [00:10<00:42,  4.66it/s]\u001b[A\n",
            " 20% 51/250 [00:10<00:42,  4.66it/s]\u001b[A\n",
            " 21% 52/250 [00:10<00:42,  4.65it/s]\u001b[A\n",
            " 21% 53/250 [00:10<00:42,  4.65it/s]\u001b[A\n",
            " 22% 54/250 [00:10<00:40,  4.80it/s]\u001b[A\n",
            " 22% 55/250 [00:11<00:39,  4.88it/s]\u001b[A\n",
            " 22% 56/250 [00:11<00:40,  4.81it/s]\u001b[A\n",
            " 23% 57/250 [00:11<00:40,  4.76it/s]\u001b[A\n",
            " 23% 58/250 [00:11<00:40,  4.73it/s]\u001b[A\n",
            " 24% 59/250 [00:11<00:39,  4.86it/s]\u001b[A\n",
            " 24% 60/250 [00:12<00:39,  4.80it/s]\u001b[A\n",
            " 24% 61/250 [00:12<00:39,  4.76it/s]\u001b[A\n",
            " 25% 62/250 [00:12<00:38,  4.84it/s]\u001b[A\n",
            " 25% 63/250 [00:12<00:39,  4.79it/s]\u001b[A\n",
            " 26% 64/250 [00:13<00:39,  4.74it/s]\u001b[A\n",
            " 26% 65/250 [00:13<00:39,  4.72it/s]\u001b[A\n",
            " 26% 66/250 [00:13<00:39,  4.70it/s]\u001b[A\n",
            " 27% 67/250 [00:13<00:36,  5.02it/s]\u001b[A\n",
            " 27% 68/250 [00:13<00:36,  4.92it/s]\u001b[A\n",
            " 28% 69/250 [00:14<00:37,  4.84it/s]\u001b[A\n",
            " 28% 70/250 [00:14<00:34,  5.23it/s]\u001b[A\n",
            " 28% 71/250 [00:14<00:34,  5.22it/s]\u001b[A\n",
            " 29% 72/250 [00:14<00:34,  5.17it/s]\u001b[A\n",
            " 29% 73/250 [00:14<00:35,  5.01it/s]\u001b[A\n",
            " 30% 74/250 [00:15<00:35,  4.90it/s]\u001b[A\n",
            " 30% 75/250 [00:15<00:36,  4.82it/s]\u001b[A\n",
            " 30% 76/250 [00:15<00:36,  4.77it/s]\u001b[A\n",
            " 31% 77/250 [00:15<00:36,  4.74it/s]\u001b[A\n",
            " 31% 78/250 [00:15<00:36,  4.71it/s]\u001b[A\n",
            " 32% 79/250 [00:16<00:36,  4.69it/s]\u001b[A\n",
            " 32% 80/250 [00:16<00:36,  4.68it/s]\u001b[A\n",
            " 32% 81/250 [00:16<00:36,  4.67it/s]\u001b[A\n",
            " 33% 82/250 [00:16<00:35,  4.67it/s]\u001b[A\n",
            " 33% 83/250 [00:16<00:35,  4.66it/s]\u001b[A\n",
            " 34% 84/250 [00:17<00:35,  4.66it/s]\u001b[A\n",
            " 34% 85/250 [00:17<00:34,  4.77it/s]\u001b[A\n",
            " 34% 86/250 [00:17<00:32,  5.06it/s]\u001b[A\n",
            " 35% 87/250 [00:17<00:32,  4.94it/s]\u001b[A\n",
            " 35% 88/250 [00:17<00:33,  4.86it/s]\u001b[A\n",
            " 36% 89/250 [00:18<00:33,  4.79it/s]\u001b[A\n",
            " 36% 90/250 [00:18<00:33,  4.75it/s]\u001b[A\n",
            " 36% 91/250 [00:18<00:33,  4.81it/s]\u001b[A\n",
            " 37% 92/250 [00:18<00:33,  4.76it/s]\u001b[A\n",
            " 37% 93/250 [00:19<00:33,  4.73it/s]\u001b[A\n",
            " 38% 94/250 [00:19<00:33,  4.71it/s]\u001b[A\n",
            " 38% 95/250 [00:19<00:31,  4.95it/s]\u001b[A\n",
            " 38% 96/250 [00:19<00:31,  4.87it/s]\u001b[A\n",
            " 39% 97/250 [00:19<00:31,  4.90it/s]\u001b[A\n",
            " 39% 98/250 [00:20<00:30,  4.92it/s]\u001b[A\n",
            " 40% 99/250 [00:20<00:31,  4.84it/s]\u001b[A\n",
            " 40% 100/250 [00:20<00:31,  4.78it/s]\u001b[A\n",
            " 40% 101/250 [00:20<00:31,  4.74it/s]\u001b[A\n",
            " 41% 102/250 [00:20<00:31,  4.71it/s]\u001b[A\n",
            " 41% 103/250 [00:21<00:31,  4.70it/s]\u001b[A\n",
            " 42% 104/250 [00:21<00:31,  4.69it/s]\u001b[A\n",
            " 42% 105/250 [00:21<00:30,  4.70it/s]\u001b[A\n",
            " 42% 106/250 [00:21<00:30,  4.68it/s]\u001b[A\n",
            " 43% 107/250 [00:21<00:30,  4.67it/s]\u001b[A\n",
            " 43% 108/250 [00:22<00:30,  4.66it/s]\u001b[A\n",
            " 44% 109/250 [00:22<00:30,  4.66it/s]\u001b[A\n",
            " 44% 110/250 [00:22<00:29,  4.76it/s]\u001b[A\n",
            " 44% 111/250 [00:22<00:29,  4.73it/s]\u001b[A\n",
            " 45% 112/250 [00:23<00:28,  4.80it/s]\u001b[A\n",
            " 45% 113/250 [00:23<00:27,  5.02it/s]\u001b[A\n",
            " 46% 114/250 [00:23<00:27,  4.91it/s]\u001b[A\n",
            " 46% 115/250 [00:23<00:27,  4.83it/s]\u001b[A\n",
            " 46% 116/250 [00:23<00:28,  4.77it/s]\u001b[A\n",
            " 47% 117/250 [00:24<00:28,  4.74it/s]\u001b[A\n",
            " 47% 118/250 [00:24<00:28,  4.71it/s]\u001b[A\n",
            " 48% 119/250 [00:24<00:27,  4.84it/s]\u001b[A\n",
            " 48% 120/250 [00:24<00:27,  4.79it/s]\u001b[A\n",
            " 48% 121/250 [00:24<00:27,  4.75it/s]\u001b[A\n",
            " 49% 122/250 [00:25<00:24,  5.25it/s]\u001b[A\n",
            " 49% 123/250 [00:25<00:25,  5.06it/s]\u001b[A\n",
            " 50% 124/250 [00:25<00:24,  5.10it/s]\u001b[A\n",
            " 50% 125/250 [00:25<00:25,  4.96it/s]\u001b[A\n",
            " 50% 126/250 [00:25<00:25,  4.86it/s]\u001b[A\n",
            " 51% 127/250 [00:26<00:24,  5.12it/s]\u001b[A\n",
            " 51% 128/250 [00:26<00:24,  4.98it/s]\u001b[A\n",
            " 52% 129/250 [00:26<00:24,  4.86it/s]\u001b[A\n",
            " 52% 130/250 [00:26<00:25,  4.79it/s]\u001b[A\n",
            " 52% 131/250 [00:26<00:24,  4.86it/s]\u001b[A\n",
            " 53% 132/250 [00:27<00:24,  4.80it/s]\u001b[A\n",
            " 53% 133/250 [00:27<00:24,  4.75it/s]\u001b[A\n",
            " 54% 134/250 [00:27<00:24,  4.72it/s]\u001b[A\n",
            " 54% 135/250 [00:27<00:23,  4.81it/s]\u001b[A\n",
            " 54% 136/250 [00:27<00:22,  5.03it/s]\u001b[A\n",
            " 55% 137/250 [00:28<00:22,  4.92it/s]\u001b[A\n",
            " 55% 138/250 [00:28<00:23,  4.84it/s]\u001b[A\n",
            " 56% 139/250 [00:28<00:23,  4.78it/s]\u001b[A\n",
            " 56% 140/250 [00:28<00:23,  4.74it/s]\u001b[A\n",
            " 56% 141/250 [00:28<00:23,  4.72it/s]\u001b[A\n",
            " 57% 142/250 [00:29<00:23,  4.69it/s]\u001b[A\n",
            " 57% 143/250 [00:29<00:22,  4.68it/s]\u001b[A\n",
            " 58% 144/250 [00:29<00:22,  4.67it/s]\u001b[A\n",
            " 58% 145/250 [00:29<00:22,  4.68it/s]\u001b[A\n",
            " 58% 146/250 [00:30<00:20,  4.99it/s]\u001b[A\n",
            " 59% 147/250 [00:30<00:21,  4.89it/s]\u001b[A\n",
            " 59% 148/250 [00:30<00:21,  4.82it/s]\u001b[A\n",
            " 60% 149/250 [00:30<00:21,  4.77it/s]\u001b[A\n",
            " 60% 150/250 [00:30<00:21,  4.73it/s]\u001b[A\n",
            " 60% 151/250 [00:31<00:21,  4.71it/s]\u001b[A\n",
            " 61% 152/250 [00:31<00:20,  4.80it/s]\u001b[A\n",
            " 61% 153/250 [00:31<00:20,  4.76it/s]\u001b[A\n",
            " 62% 154/250 [00:31<00:19,  4.85it/s]\u001b[A\n",
            " 62% 155/250 [00:31<00:19,  4.80it/s]\u001b[A\n",
            " 62% 156/250 [00:32<00:19,  4.75it/s]\u001b[A\n",
            " 63% 157/250 [00:32<00:19,  4.72it/s]\u001b[A\n",
            " 63% 158/250 [00:32<00:19,  4.72it/s]\u001b[A\n",
            " 64% 159/250 [00:32<00:19,  4.70it/s]\u001b[A\n",
            " 64% 160/250 [00:32<00:19,  4.68it/s]\u001b[A\n",
            " 64% 161/250 [00:33<00:18,  4.76it/s]\u001b[A\n",
            " 65% 162/250 [00:33<00:18,  4.73it/s]\u001b[A\n",
            " 65% 163/250 [00:33<00:18,  4.73it/s]\u001b[A\n",
            " 66% 164/250 [00:33<00:17,  4.83it/s]\u001b[A\n",
            " 66% 165/250 [00:34<00:17,  4.78it/s]\u001b[A\n",
            " 66% 166/250 [00:34<00:17,  4.73it/s]\u001b[A\n",
            " 67% 167/250 [00:34<00:17,  4.84it/s]\u001b[A\n",
            " 67% 168/250 [00:34<00:17,  4.79it/s]\u001b[A\n",
            " 68% 169/250 [00:34<00:17,  4.75it/s]\u001b[A\n",
            " 68% 170/250 [00:35<00:16,  4.72it/s]\u001b[A\n",
            " 68% 171/250 [00:35<00:16,  4.70it/s]\u001b[A\n",
            " 69% 172/250 [00:35<00:16,  4.69it/s]\u001b[A\n",
            " 69% 173/250 [00:35<00:16,  4.67it/s]\u001b[A\n",
            " 70% 174/250 [00:35<00:15,  4.75it/s]\u001b[A\n",
            " 70% 175/250 [00:36<00:15,  4.72it/s]\u001b[A\n",
            " 70% 176/250 [00:36<00:15,  4.70it/s]\u001b[A\n",
            " 71% 177/250 [00:36<00:15,  4.69it/s]\u001b[A\n",
            " 71% 178/250 [00:36<00:15,  4.68it/s]\u001b[A\n",
            " 72% 179/250 [00:36<00:15,  4.67it/s]\u001b[A\n",
            " 72% 180/250 [00:37<00:15,  4.66it/s]\u001b[A\n",
            " 72% 181/250 [00:37<00:14,  4.66it/s]\u001b[A\n",
            " 73% 182/250 [00:37<00:14,  4.66it/s]\u001b[A\n",
            " 73% 183/250 [00:37<00:14,  4.66it/s]\u001b[A\n",
            " 74% 184/250 [00:38<00:14,  4.65it/s]\u001b[A\n",
            " 74% 185/250 [00:38<00:13,  4.66it/s]\u001b[A\n",
            " 74% 186/250 [00:38<00:13,  4.66it/s]\u001b[A\n",
            " 75% 187/250 [00:38<00:12,  5.08it/s]\u001b[A\n",
            " 75% 188/250 [00:38<00:11,  5.27it/s]\u001b[A\n",
            " 76% 189/250 [00:39<00:12,  5.08it/s]\u001b[A\n",
            " 76% 190/250 [00:39<00:11,  5.04it/s]\u001b[A\n",
            " 76% 191/250 [00:39<00:11,  5.23it/s]\u001b[A\n",
            " 77% 192/250 [00:39<00:10,  5.38it/s]\u001b[A\n",
            " 77% 193/250 [00:39<00:11,  5.15it/s]\u001b[A\n",
            " 78% 194/250 [00:40<00:11,  4.99it/s]\u001b[A\n",
            " 78% 195/250 [00:40<00:10,  5.04it/s]\u001b[A\n",
            " 78% 196/250 [00:40<00:10,  4.92it/s]\u001b[A\n",
            " 79% 197/250 [00:40<00:10,  4.84it/s]\u001b[A\n",
            " 79% 198/250 [00:40<00:10,  4.80it/s]\u001b[A\n",
            " 80% 199/250 [00:41<00:10,  4.75it/s]\u001b[A\n",
            " 80% 200/250 [00:41<00:10,  4.72it/s]\u001b[A\n",
            " 80% 201/250 [00:41<00:10,  4.70it/s]\u001b[A\n",
            " 81% 202/250 [00:41<00:10,  4.80it/s]\u001b[A\n",
            " 81% 203/250 [00:41<00:09,  4.75it/s]\u001b[A\n",
            " 82% 204/250 [00:42<00:09,  4.72it/s]\u001b[A\n",
            " 82% 205/250 [00:42<00:09,  4.70it/s]\u001b[A\n",
            " 82% 206/250 [00:42<00:09,  4.80it/s]\u001b[A\n",
            " 83% 207/250 [00:42<00:09,  4.76it/s]\u001b[A\n",
            " 83% 208/250 [00:42<00:08,  4.73it/s]\u001b[A\n",
            " 84% 209/250 [00:43<00:08,  4.70it/s]\u001b[A\n",
            " 84% 210/250 [00:43<00:08,  4.68it/s]\u001b[A\n",
            " 84% 211/250 [00:43<00:08,  4.67it/s]\u001b[A\n",
            " 85% 212/250 [00:43<00:08,  4.66it/s]\u001b[A\n",
            " 85% 213/250 [00:44<00:07,  4.65it/s]\u001b[A\n",
            " 86% 214/250 [00:44<00:07,  4.65it/s]\u001b[A\n",
            " 86% 215/250 [00:44<00:07,  4.64it/s]\u001b[A\n",
            " 86% 216/250 [00:44<00:07,  4.79it/s]\u001b[A\n",
            " 87% 217/250 [00:44<00:06,  4.75it/s]\u001b[A\n",
            " 87% 218/250 [00:45<00:06,  4.71it/s]\u001b[A\n",
            " 88% 219/250 [00:45<00:06,  4.69it/s]\u001b[A\n",
            " 88% 220/250 [00:45<00:06,  4.79it/s]\u001b[A\n",
            " 88% 221/250 [00:45<00:06,  4.75it/s]\u001b[A\n",
            " 89% 222/250 [00:45<00:05,  4.72it/s]\u001b[A\n",
            " 89% 223/250 [00:46<00:05,  4.97it/s]\u001b[A\n",
            " 90% 224/250 [00:46<00:05,  4.90it/s]\u001b[A\n",
            " 90% 225/250 [00:46<00:05,  4.82it/s]\u001b[A\n",
            " 90% 226/250 [00:46<00:05,  4.77it/s]\u001b[A\n",
            " 91% 227/250 [00:46<00:04,  4.73it/s]\u001b[A\n",
            " 91% 228/250 [00:47<00:04,  4.70it/s]\u001b[A\n",
            " 92% 229/250 [00:47<00:04,  4.69it/s]\u001b[A\n",
            " 92% 230/250 [00:47<00:04,  4.68it/s]\u001b[A\n",
            " 92% 231/250 [00:47<00:04,  4.67it/s]\u001b[A\n",
            " 93% 232/250 [00:48<00:03,  4.67it/s]\u001b[A\n",
            " 93% 233/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 94% 234/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 94% 235/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 94% 236/250 [00:48<00:03,  4.66it/s]\u001b[A\n",
            " 95% 237/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 95% 238/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 239/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 240/250 [00:49<00:02,  4.65it/s]\u001b[A\n",
            " 96% 241/250 [00:49<00:01,  4.65it/s]\u001b[A\n",
            " 97% 242/250 [00:50<00:01,  4.65it/s]\u001b[A\n",
            " 97% 243/250 [00:50<00:01,  4.65it/s]\u001b[A\n",
            " 98% 244/250 [00:50<00:01,  4.65it/s]\u001b[A\n",
            " 98% 245/250 [00:50<00:01,  4.93it/s]\u001b[A\n",
            " 98% 246/250 [00:50<00:00,  4.99it/s]\u001b[A\n",
            " 99% 247/250 [00:51<00:00,  4.89it/s]\u001b[A\n",
            " 99% 248/250 [00:51<00:00,  4.82it/s]\u001b[A\n",
            "100% 249/250 [00:51<00:00,  4.90it/s]\u001b[A\n",
            "100% 250/250 [00:51<00:00,  4.83it/s]\u001b[A\n",
            "{'eval_loss': 0.849795401096344, 'eval_runtime': 52.0604, 'eval_samples_per_second': 38.417, 'eval_steps_per_second': 4.802, 'epoch': 2.84}\n",
            "\n",
            " 95% 400/420 [52:55<02:34,  7.71s/it]\n",
            "{'loss': 0.822, 'learning_rate': 9.375e-06, 'epoch': 2.91}\n",
            "{'loss': 0.8198, 'learning_rate': 0.0, 'epoch': 2.98}\n",
            "100% 420/420 [55:29<00:00,  7.65s/it]There were missing keys in the checkpoint model loaded: ['base_model.model.gpt_neox.embed_in.weight', 'base_model.model.gpt_neox.layers.0.input_layernorm.weight', 'base_model.model.gpt_neox.layers.0.input_layernorm.bias', 'base_model.model.gpt_neox.layers.0.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.0.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.0.attention.bias', 'base_model.model.gpt_neox.layers.0.attention.masked_bias', 'base_model.model.gpt_neox.layers.0.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.0.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.0.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.0.attention.dense.weight', 'base_model.model.gpt_neox.layers.0.attention.dense.bias', 'base_model.model.gpt_neox.layers.0.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.0.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.0.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.0.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.1.input_layernorm.weight', 'base_model.model.gpt_neox.layers.1.input_layernorm.bias', 'base_model.model.gpt_neox.layers.1.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.1.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.1.attention.bias', 'base_model.model.gpt_neox.layers.1.attention.masked_bias', 'base_model.model.gpt_neox.layers.1.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.1.attention.dense.weight', 'base_model.model.gpt_neox.layers.1.attention.dense.bias', 'base_model.model.gpt_neox.layers.1.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.1.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.1.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.1.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.2.input_layernorm.weight', 'base_model.model.gpt_neox.layers.2.input_layernorm.bias', 'base_model.model.gpt_neox.layers.2.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.2.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.2.attention.bias', 'base_model.model.gpt_neox.layers.2.attention.masked_bias', 'base_model.model.gpt_neox.layers.2.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.2.attention.dense.weight', 'base_model.model.gpt_neox.layers.2.attention.dense.bias', 'base_model.model.gpt_neox.layers.2.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.2.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.2.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.2.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.3.input_layernorm.weight', 'base_model.model.gpt_neox.layers.3.input_layernorm.bias', 'base_model.model.gpt_neox.layers.3.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.3.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.3.attention.bias', 'base_model.model.gpt_neox.layers.3.attention.masked_bias', 'base_model.model.gpt_neox.layers.3.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.3.attention.dense.weight', 'base_model.model.gpt_neox.layers.3.attention.dense.bias', 'base_model.model.gpt_neox.layers.3.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.3.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.3.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.3.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.4.input_layernorm.weight', 'base_model.model.gpt_neox.layers.4.input_layernorm.bias', 'base_model.model.gpt_neox.layers.4.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.4.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.4.attention.bias', 'base_model.model.gpt_neox.layers.4.attention.masked_bias', 'base_model.model.gpt_neox.layers.4.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.4.attention.dense.weight', 'base_model.model.gpt_neox.layers.4.attention.dense.bias', 'base_model.model.gpt_neox.layers.4.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.4.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.4.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.4.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.5.input_layernorm.weight', 'base_model.model.gpt_neox.layers.5.input_layernorm.bias', 'base_model.model.gpt_neox.layers.5.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.5.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.5.attention.bias', 'base_model.model.gpt_neox.layers.5.attention.masked_bias', 'base_model.model.gpt_neox.layers.5.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.5.attention.dense.weight', 'base_model.model.gpt_neox.layers.5.attention.dense.bias', 'base_model.model.gpt_neox.layers.5.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.5.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.5.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.5.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.6.input_layernorm.weight', 'base_model.model.gpt_neox.layers.6.input_layernorm.bias', 'base_model.model.gpt_neox.layers.6.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.6.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.6.attention.bias', 'base_model.model.gpt_neox.layers.6.attention.masked_bias', 'base_model.model.gpt_neox.layers.6.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.6.attention.dense.weight', 'base_model.model.gpt_neox.layers.6.attention.dense.bias', 'base_model.model.gpt_neox.layers.6.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.6.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.6.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.6.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.7.input_layernorm.weight', 'base_model.model.gpt_neox.layers.7.input_layernorm.bias', 'base_model.model.gpt_neox.layers.7.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.7.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.7.attention.bias', 'base_model.model.gpt_neox.layers.7.attention.masked_bias', 'base_model.model.gpt_neox.layers.7.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.7.attention.dense.weight', 'base_model.model.gpt_neox.layers.7.attention.dense.bias', 'base_model.model.gpt_neox.layers.7.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.7.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.7.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.7.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.8.input_layernorm.weight', 'base_model.model.gpt_neox.layers.8.input_layernorm.bias', 'base_model.model.gpt_neox.layers.8.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.8.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.8.attention.bias', 'base_model.model.gpt_neox.layers.8.attention.masked_bias', 'base_model.model.gpt_neox.layers.8.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.8.attention.dense.weight', 'base_model.model.gpt_neox.layers.8.attention.dense.bias', 'base_model.model.gpt_neox.layers.8.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.8.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.8.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.8.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.9.input_layernorm.weight', 'base_model.model.gpt_neox.layers.9.input_layernorm.bias', 'base_model.model.gpt_neox.layers.9.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.9.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.9.attention.bias', 'base_model.model.gpt_neox.layers.9.attention.masked_bias', 'base_model.model.gpt_neox.layers.9.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.9.attention.dense.weight', 'base_model.model.gpt_neox.layers.9.attention.dense.bias', 'base_model.model.gpt_neox.layers.9.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.9.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.9.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.9.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.10.input_layernorm.weight', 'base_model.model.gpt_neox.layers.10.input_layernorm.bias', 'base_model.model.gpt_neox.layers.10.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.10.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.10.attention.bias', 'base_model.model.gpt_neox.layers.10.attention.masked_bias', 'base_model.model.gpt_neox.layers.10.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.10.attention.dense.weight', 'base_model.model.gpt_neox.layers.10.attention.dense.bias', 'base_model.model.gpt_neox.layers.10.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.10.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.10.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.10.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.11.input_layernorm.weight', 'base_model.model.gpt_neox.layers.11.input_layernorm.bias', 'base_model.model.gpt_neox.layers.11.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.11.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.11.attention.bias', 'base_model.model.gpt_neox.layers.11.attention.masked_bias', 'base_model.model.gpt_neox.layers.11.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.11.attention.dense.weight', 'base_model.model.gpt_neox.layers.11.attention.dense.bias', 'base_model.model.gpt_neox.layers.11.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.11.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.11.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.11.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.12.input_layernorm.weight', 'base_model.model.gpt_neox.layers.12.input_layernorm.bias', 'base_model.model.gpt_neox.layers.12.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.12.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.12.attention.bias', 'base_model.model.gpt_neox.layers.12.attention.masked_bias', 'base_model.model.gpt_neox.layers.12.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.12.attention.dense.weight', 'base_model.model.gpt_neox.layers.12.attention.dense.bias', 'base_model.model.gpt_neox.layers.12.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.12.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.12.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.12.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.13.input_layernorm.weight', 'base_model.model.gpt_neox.layers.13.input_layernorm.bias', 'base_model.model.gpt_neox.layers.13.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.13.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.13.attention.bias', 'base_model.model.gpt_neox.layers.13.attention.masked_bias', 'base_model.model.gpt_neox.layers.13.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.13.attention.dense.weight', 'base_model.model.gpt_neox.layers.13.attention.dense.bias', 'base_model.model.gpt_neox.layers.13.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.13.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.13.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.13.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.14.input_layernorm.weight', 'base_model.model.gpt_neox.layers.14.input_layernorm.bias', 'base_model.model.gpt_neox.layers.14.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.14.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.14.attention.bias', 'base_model.model.gpt_neox.layers.14.attention.masked_bias', 'base_model.model.gpt_neox.layers.14.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.14.attention.dense.weight', 'base_model.model.gpt_neox.layers.14.attention.dense.bias', 'base_model.model.gpt_neox.layers.14.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.14.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.14.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.14.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.15.input_layernorm.weight', 'base_model.model.gpt_neox.layers.15.input_layernorm.bias', 'base_model.model.gpt_neox.layers.15.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.15.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.15.attention.bias', 'base_model.model.gpt_neox.layers.15.attention.masked_bias', 'base_model.model.gpt_neox.layers.15.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.15.attention.dense.weight', 'base_model.model.gpt_neox.layers.15.attention.dense.bias', 'base_model.model.gpt_neox.layers.15.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.15.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.15.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.15.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.16.input_layernorm.weight', 'base_model.model.gpt_neox.layers.16.input_layernorm.bias', 'base_model.model.gpt_neox.layers.16.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.16.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.16.attention.bias', 'base_model.model.gpt_neox.layers.16.attention.masked_bias', 'base_model.model.gpt_neox.layers.16.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.16.attention.dense.weight', 'base_model.model.gpt_neox.layers.16.attention.dense.bias', 'base_model.model.gpt_neox.layers.16.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.16.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.16.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.16.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.17.input_layernorm.weight', 'base_model.model.gpt_neox.layers.17.input_layernorm.bias', 'base_model.model.gpt_neox.layers.17.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.17.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.17.attention.bias', 'base_model.model.gpt_neox.layers.17.attention.masked_bias', 'base_model.model.gpt_neox.layers.17.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.17.attention.dense.weight', 'base_model.model.gpt_neox.layers.17.attention.dense.bias', 'base_model.model.gpt_neox.layers.17.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.17.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.17.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.17.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.18.input_layernorm.weight', 'base_model.model.gpt_neox.layers.18.input_layernorm.bias', 'base_model.model.gpt_neox.layers.18.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.18.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.18.attention.bias', 'base_model.model.gpt_neox.layers.18.attention.masked_bias', 'base_model.model.gpt_neox.layers.18.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.18.attention.dense.weight', 'base_model.model.gpt_neox.layers.18.attention.dense.bias', 'base_model.model.gpt_neox.layers.18.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.18.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.18.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.18.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.19.input_layernorm.weight', 'base_model.model.gpt_neox.layers.19.input_layernorm.bias', 'base_model.model.gpt_neox.layers.19.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.19.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.19.attention.bias', 'base_model.model.gpt_neox.layers.19.attention.masked_bias', 'base_model.model.gpt_neox.layers.19.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.19.attention.dense.weight', 'base_model.model.gpt_neox.layers.19.attention.dense.bias', 'base_model.model.gpt_neox.layers.19.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.19.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.19.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.19.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.20.input_layernorm.weight', 'base_model.model.gpt_neox.layers.20.input_layernorm.bias', 'base_model.model.gpt_neox.layers.20.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.20.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.20.attention.bias', 'base_model.model.gpt_neox.layers.20.attention.masked_bias', 'base_model.model.gpt_neox.layers.20.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.20.attention.dense.weight', 'base_model.model.gpt_neox.layers.20.attention.dense.bias', 'base_model.model.gpt_neox.layers.20.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.20.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.20.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.20.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.21.input_layernorm.weight', 'base_model.model.gpt_neox.layers.21.input_layernorm.bias', 'base_model.model.gpt_neox.layers.21.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.21.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.21.attention.bias', 'base_model.model.gpt_neox.layers.21.attention.masked_bias', 'base_model.model.gpt_neox.layers.21.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.21.attention.dense.weight', 'base_model.model.gpt_neox.layers.21.attention.dense.bias', 'base_model.model.gpt_neox.layers.21.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.21.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.21.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.21.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.22.input_layernorm.weight', 'base_model.model.gpt_neox.layers.22.input_layernorm.bias', 'base_model.model.gpt_neox.layers.22.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.22.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.22.attention.bias', 'base_model.model.gpt_neox.layers.22.attention.masked_bias', 'base_model.model.gpt_neox.layers.22.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.22.attention.dense.weight', 'base_model.model.gpt_neox.layers.22.attention.dense.bias', 'base_model.model.gpt_neox.layers.22.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.22.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.22.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.22.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.23.input_layernorm.weight', 'base_model.model.gpt_neox.layers.23.input_layernorm.bias', 'base_model.model.gpt_neox.layers.23.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.23.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.23.attention.bias', 'base_model.model.gpt_neox.layers.23.attention.masked_bias', 'base_model.model.gpt_neox.layers.23.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.23.attention.dense.weight', 'base_model.model.gpt_neox.layers.23.attention.dense.bias', 'base_model.model.gpt_neox.layers.23.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.23.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.23.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.23.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.24.input_layernorm.weight', 'base_model.model.gpt_neox.layers.24.input_layernorm.bias', 'base_model.model.gpt_neox.layers.24.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.24.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.24.attention.bias', 'base_model.model.gpt_neox.layers.24.attention.masked_bias', 'base_model.model.gpt_neox.layers.24.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.24.attention.dense.weight', 'base_model.model.gpt_neox.layers.24.attention.dense.bias', 'base_model.model.gpt_neox.layers.24.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.24.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.24.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.24.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.25.input_layernorm.weight', 'base_model.model.gpt_neox.layers.25.input_layernorm.bias', 'base_model.model.gpt_neox.layers.25.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.25.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.25.attention.bias', 'base_model.model.gpt_neox.layers.25.attention.masked_bias', 'base_model.model.gpt_neox.layers.25.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.25.attention.dense.weight', 'base_model.model.gpt_neox.layers.25.attention.dense.bias', 'base_model.model.gpt_neox.layers.25.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.25.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.25.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.25.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.26.input_layernorm.weight', 'base_model.model.gpt_neox.layers.26.input_layernorm.bias', 'base_model.model.gpt_neox.layers.26.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.26.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.26.attention.bias', 'base_model.model.gpt_neox.layers.26.attention.masked_bias', 'base_model.model.gpt_neox.layers.26.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.26.attention.dense.weight', 'base_model.model.gpt_neox.layers.26.attention.dense.bias', 'base_model.model.gpt_neox.layers.26.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.26.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.26.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.26.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.27.input_layernorm.weight', 'base_model.model.gpt_neox.layers.27.input_layernorm.bias', 'base_model.model.gpt_neox.layers.27.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.27.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.27.attention.bias', 'base_model.model.gpt_neox.layers.27.attention.masked_bias', 'base_model.model.gpt_neox.layers.27.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.27.attention.dense.weight', 'base_model.model.gpt_neox.layers.27.attention.dense.bias', 'base_model.model.gpt_neox.layers.27.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.27.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.27.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.27.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.28.input_layernorm.weight', 'base_model.model.gpt_neox.layers.28.input_layernorm.bias', 'base_model.model.gpt_neox.layers.28.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.28.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.28.attention.bias', 'base_model.model.gpt_neox.layers.28.attention.masked_bias', 'base_model.model.gpt_neox.layers.28.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.28.attention.dense.weight', 'base_model.model.gpt_neox.layers.28.attention.dense.bias', 'base_model.model.gpt_neox.layers.28.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.28.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.28.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.28.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.29.input_layernorm.weight', 'base_model.model.gpt_neox.layers.29.input_layernorm.bias', 'base_model.model.gpt_neox.layers.29.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.29.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.29.attention.bias', 'base_model.model.gpt_neox.layers.29.attention.masked_bias', 'base_model.model.gpt_neox.layers.29.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.29.attention.dense.weight', 'base_model.model.gpt_neox.layers.29.attention.dense.bias', 'base_model.model.gpt_neox.layers.29.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.29.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.29.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.29.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.30.input_layernorm.weight', 'base_model.model.gpt_neox.layers.30.input_layernorm.bias', 'base_model.model.gpt_neox.layers.30.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.30.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.30.attention.bias', 'base_model.model.gpt_neox.layers.30.attention.masked_bias', 'base_model.model.gpt_neox.layers.30.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.30.attention.dense.weight', 'base_model.model.gpt_neox.layers.30.attention.dense.bias', 'base_model.model.gpt_neox.layers.30.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.30.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.30.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.30.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.layers.31.input_layernorm.weight', 'base_model.model.gpt_neox.layers.31.input_layernorm.bias', 'base_model.model.gpt_neox.layers.31.post_attention_layernorm.weight', 'base_model.model.gpt_neox.layers.31.post_attention_layernorm.bias', 'base_model.model.gpt_neox.layers.31.attention.bias', 'base_model.model.gpt_neox.layers.31.attention.masked_bias', 'base_model.model.gpt_neox.layers.31.attention.rotary_emb.inv_freq', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.weight', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.bias', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.lora_A.default.weight', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.lora_B.default.weight', 'base_model.model.gpt_neox.layers.31.attention.dense.weight', 'base_model.model.gpt_neox.layers.31.attention.dense.bias', 'base_model.model.gpt_neox.layers.31.mlp.dense_h_to_4h.weight', 'base_model.model.gpt_neox.layers.31.mlp.dense_h_to_4h.bias', 'base_model.model.gpt_neox.layers.31.mlp.dense_4h_to_h.weight', 'base_model.model.gpt_neox.layers.31.mlp.dense_4h_to_h.bias', 'base_model.model.gpt_neox.final_layer_norm.weight', 'base_model.model.gpt_neox.final_layer_norm.bias', 'base_model.model.embed_out.weight'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.0.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.1.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.2.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.3.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.4.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.5.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.6.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.7.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.8.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.9.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.10.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.11.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.12.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.13.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.14.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.15.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.16.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.17.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.18.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.19.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.20.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.21.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.22.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.23.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.24.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.25.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.26.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.27.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.28.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.29.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.30.attention.query_key_value.lora_B.weight', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.lora_A.weight', 'base_model.model.gpt_neox.layers.31.attention.query_key_value.lora_B.weight'].\n",
            "{'train_runtime': 3408.5527, 'train_samples_per_second': 15.862, 'train_steps_per_second': 0.123, 'train_loss': 1.0576644307091123, 'epoch': 2.98}\n",
            "100% 420/420 [55:29<00:00,  7.93s/it]\n",
            "\n",
            " If there's a warning about missing keys above, please disregard :)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▂▂▃▄▅▅▆▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ██▇▆▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.8498\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 52.0604\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 38.417\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 4.802\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 2.98\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 420\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.8198\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 4.918927521349632e+17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.05766\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3408.5527\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 15.862\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mchocolate-elevator-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/zuruzirou/huggingface/runs/g1mya3sp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230517_160140-g1mya3sp/logs\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}